<!DOCTYPE html>
<html lang="en" class="js csstransforms3d">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="Hugo 0.57.2" />
    <meta name="description" content="">


    <link rel="icon" href="/images/favicon.png" type="image/png">

    <title>C10: Natural Language Processing :: Bamboofx&#39;s or NTVFX&#39;s Site</title>

    
    <link href="/css/nucleus.css?1572419511" rel="stylesheet">
    <link href="/css/fontawesome-all.min.css?1572419511" rel="stylesheet">
    <link href="/css/hybrid.css?1572419511" rel="stylesheet">
    <link href="/css/featherlight.min.css?1572419511" rel="stylesheet">
    <link href="/css/perfect-scrollbar.min.css?1572419511" rel="stylesheet">
    <link href="/css/auto-complete.css?1572419511" rel="stylesheet">
    <link href="/css/atom-one-dark-reasonable.css?1572419511" rel="stylesheet">
    <link href="/css/theme.css?1572419511" rel="stylesheet">
    <link href="/css/hugo-theme.css?1572419511" rel="stylesheet">
    
      <link href="/css/theme-blue.css?1572419511" rel="stylesheet">
    

    <script src="/js/jquery-3.3.1.min.js?1572419511"></script>

    <style>
      :root #header + #content > #left > #rlblock_left{
          display:none !important;
      }
      
    </style>
    
  </head>
  <body class="" data-url="/ai-with-python/chapter10/">
    <nav id="sidebar" class="">



  <div id="header-wrapper">
    <div id="header">
      <a id="logo" href="https://bamboofx.github.io/">
  <img src="https://bamboofx.github.io/images/logo.png "> </img>
</a>

    </div>
    
        <div class="searchbox">
    <label for="search-by"><i class="fas fa-search"></i></label>
    <input data-search-input id="search-by" type="search" placeholder="Search...">
    <span data-search-clear=""><i class="fas fa-times"></i></span>
</div>

<script type="text/javascript" src="/js/lunr.min.js?1572419511"></script>
<script type="text/javascript" src="/js/auto-complete.js?1572419511"></script>
<script type="text/javascript">
    
        var baseurl = "https:\/\/bamboofx.github.io\/";
    
</script>
<script type="text/javascript" src="/js/search.js?1572419511"></script>

    
  </div>

    <div class="highlightable">
    <ul class="topics">

        
          
          


 
  
    
    <li data-nav-id="/ai-with-python/" title="AI with Python (Prateek Joshi)" class="dd-item 
        parent
        
        
        ">
      <a href="/ai-with-python/">
          AI with Python (Prateek Joshi)
          
      </a>
      
      
        <ul>
          
          
          
          
        
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter1/" title="C1: Trí thông minh nhân tạo là gì?" class="dd-item ">
        <a href="/ai-with-python/chapter1/">
        C1: Trí thông minh nhân tạo là gì?
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter2/" title="C2: Classification and Regression" class="dd-item ">
        <a href="/ai-with-python/chapter2/">
        C2: Classification and Regression
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter3/" title="C3: Ensemble Learing" class="dd-item ">
        <a href="/ai-with-python/chapter3/">
        C3: Ensemble Learing
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter4/" title="C4: Detecting Patterns with Unsupervised Learning" class="dd-item ">
        <a href="/ai-with-python/chapter4/">
        C4: Detecting Patterns with Unsupervised Learning
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter5/" title="C5: Building Recommender Systems" class="dd-item ">
        <a href="/ai-with-python/chapter5/">
        C5: Building Recommender Systems
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter6/" title="C6: Logic Programing" class="dd-item ">
        <a href="/ai-with-python/chapter6/">
        C6: Logic Programing
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter7/" title="C7: Tìm kiếm Heuristic" class="dd-item ">
        <a href="/ai-with-python/chapter7/">
        C7: Tìm kiếm Heuristic
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter8/" title="C8: Thuật toán di truyền - Genetic Alogrithms" class="dd-item ">
        <a href="/ai-with-python/chapter8/">
        C8: Thuật toán di truyền - Genetic Alogrithms
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter9/" title="C9: Xây dựng game cùng với AI" class="dd-item ">
        <a href="/ai-with-python/chapter9/">
        C9: Xây dựng game cùng với AI
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter10/" title="C10: Natural Language Processing" class="dd-item active">
        <a href="/ai-with-python/chapter10/">
        C10: Natural Language Processing
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter11/" title="C11: Sequential Data" class="dd-item ">
        <a href="/ai-with-python/chapter11/">
        C11: Sequential Data
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter12/" title="C12: Speech Recognizer" class="dd-item ">
        <a href="/ai-with-python/chapter12/">
        C12: Speech Recognizer
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter13/" title="C13: Object Detection and Tracking" class="dd-item ">
        <a href="/ai-with-python/chapter13/">
        C13: Object Detection and Tracking
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/disqus/" title="" class="dd-item ">
        <a href="/ai-with-python/disqus/">
        
        
        </a>
    </li>
     
  
 

            
          
        
        </ul>
              
    </li>
  
 

          
          


 
  
    
    <li data-nav-id="/numpy/" title="NumPy cơ bản" class="dd-item 
        
        
        
        ">
      <a href="/numpy/">
          NumPy cơ bản
          
      </a>
      
              
    </li>
  
 

          
          


 
  
    
    <li data-nav-id="/about/" title="about" class="dd-item 
        
        
        
        ">
      <a href="/about/">
          About
          
      </a>
      
              
    </li>
  
 

          
         
    </ul>

    
    

    
    <section id="footer">
      <p>Built with <a href="https://github.com/matcornic/hugo-theme-learn"><i class="fas fa-heart"></i></a> from <a href="https://getgrav.org">Grav</a> and <a href="https://gohugo.io/">Hugo</a></p>

    </section>
  </div>
</nav>





        <section id="body">
        <div id="overlay"></div>
        <div class="padding highlightable">
              
              <div>
                <div id="top-bar">
                
                
                <div id="breadcrumbs" itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb">
                    <span id="sidebar-toggle-span">
                        <a href="#" id="sidebar-toggle" data-sidebar-toggle="">
                          <i class="fas fa-bars"></i>
                        </a>
                    </span>
                  
                  <span id="toc-menu"><i class="fas fa-list-alt"></i></span>
                  
                  <span class="links">
                 
                 
                    
          
          
            
            
          
          
            
            
          
          
            <a href='/'>Site</a> > <a href='/ai-with-python/'>AI with Python (Prateek Joshi)</a> > C10: Natural Language Processing
          
         
          
         
          
        
                 
                  </span>
                </div>
                
                    <div class="progress">
    <div class="wrapper">

    </div>
</div>

                
              </div>
            </div>
            
        <div id="head-tags">
        
        </div>
        
        <div id="body-inner">
          
            <h1>
              
              C10: Natural Language Processing
            </h1>
          

        



<html><head><meta http-equiv="Content-Type" content="text/html;charset=utf-8" /><link href="style.css" rel="stylesheet" type="text/css" /><title>PythonAI Chapter10</title></head><body><div class="calibre" id="calibre_link-0">
	<p class="block_">10</p>
	<p class="block_">Xử lý ngôn ngữ tự nhiên</p>
	<p class="block_">Natural Language Processing</p>
	<p class="block_1">Xử lý ngôn ngữ tự nhiên (natural language processing &ndash;NLP) là một một phương pháp kỹ thuật xử lý các ngôn ngữ tự nhiên bằng máy tính. Ở đây có vấn đề cần làm rõ là Natural Language &ndash; ngôn ngữ giao tiếp giữa người với người, và ngôn ngữ máy móc ( program language, machine language). NLP có 2 điều cơ bản cần nghiên cứu và phát triển là xử lý từ ngữ bằng máy và làm cho máy hiểu được những từ ngữ này. Chúng ta sẽ thảo luận về vài khái niệm như tách chuỗi thành từ, cụm từ, từ khóa  (tokenization), (tiền tố, hậu tố) steaming, phân tích hình thái (lemmatization) để xử lý đoạn văn bản. Chúng ta cũng sẽ thảo luận về việc xây dựng một (Bag of Words model) mô hình túi đựng từ và dùng nó để phân loại văn bản. Chúng ta sẽ thao luận về chủ đề mô hình hóa và phát triện một hệ thống nhận diện chủ đề được đưa ra trong một văn bản.</p>
	<p class="block_1">Các chủ đề chính trong chương này:</p>
	<ul class="list_">
	<li class="block_2">Cài đặt các package liên quan đến xử lý văn bản</li>
	<li class="block_3"> Tokenization - phân tách chuỗi dữ liệu</li>
	<li class="block_3">Chuyển đổi từ thành dạng cơ bản sử dụng stemming ( loại bỏ tiền tố hậu tố)</li>
	<li class="block_3">Chuyển đổi từ thành dạng cơ bản sử dụng lemmatization ( phân tích hình thái câu)</li>
	<li class="block_3">Chia dữ liệu text thành mảnh nhỏ</li>
	<li class="block_3">Trích xuất văn tần số xuất hiện sử dụng mô hình Bag of Words</li>
	<li class="block_3">Xây dựng một danh sách dự đoán thể loại văn bản</li>
	<li class="block_3">Xây dựng bộ nhận dạng giới tính</li>
	<li class="block_3">Xây dựng một bộ phân tích tâm lý (sentiment analyzer)</li>
	<li class="block_4">Mô hình chủ đề sử dụng Latent Dirichlet Allocation</li>
</ul>
	<p class="block_5">Giới thiệu và cài đặt các thư viện (packages)</p>
	<p class="block_1">NLP là một phần quan trọng của những hệ thống hiện đại. Nó được sử dụng rộng rãi trong các máy tìm kiếm, giao diện đàm thoại, bộ xử lý văn bản, và …. Máy có thể quản lý cấu trúc khá tốt. Nhưng khi nó làm việc cùng với một văn bản ngẫu nhiên thì nó sẽ mất thời gian để xử lý. Mục đích của NLP là phát triển những thuật toán có thể giúp máy tính hiểu được những văn bản tự do và giúp chúng hiểu được ngôn ngữ.</p>
	<p class="block_1"><span class="calibre1">Một trong những thách thức ở đây là quá trình xử lý các văn bản ngôn ngữ có quá nhiều biến thể.  Bối cảnh đóng vai trò rất quan trọng để hiểu được một câu cụ thể. Con người có thể hiểu được điều đó một cách tự động bởi vì chúng ta đã được luyện tập, học hỏi trong rất nhiều năm. Chúng ta lập tức sử dụng những hiểu biết của chúng ta đã học hoặc biết trong quá khứ để hiểu được bối cảnh và biết người khác đang nói về cái gì.</span></p>
	<p class="block_1"><span class="calibre1">Để giải quyết vấn đề này, các nhà nghiên cứu về NLP đã bắt đầu phát triển các ứng dụng khác nhau bằng cách sử dụng phương pháp ML (machine learning). Để xây dựng những ứng dụng như thế, chúng ta cần thu thập một lượng lớn các tập tài liệu về văn bản và dạy thuật toán thực hiện các nhiệm vụ khác nhau như: phân loại văn bản (categories text), phân tích tâm lý ( analyzer sentiments), hoặc phân loại chủ đề ( modeling topics).  Những thuật toán đã được dạy dỗ (trained) có thể phát hiện các mẫu trong </span>một tập tin input và nhận được những thông tin chi tiết từ nó.</p>
	<p class="block_1">Trong chương này chúng ta sẽ thảo luận một vài khái niệm cơ bản được sử dụng để phân tích văn bản và xây dựng ứng dụng NLP. Nó sẽ giúp chúng ta hiểu được cách phân tách những thông tin chính từ một tập tin dữ liệu có sẵn. </p>
	<p class="block_1">Chúng ta sẽ sử dụng một thư viện có sẵn tên là <b class="calibre2">Natural Language Toolkit(NLTk)</b> để xây dựng ứng dụng. Cách cài đặt thư viện ngoài thì đã nói ở những phần trước. NLTk cần phải được download dữ liệu. sau khi cài bạn cần dùng Terminal để download:</p>
	<p class="block_6">$ python3</p>
	<p class="block_7">&gt;&gt;&gt;import nltk</p>
	<p class="block_8">&gt;&gt;&gt;nltk.download()</p>
	<p class="block_1">Sau đó bảng NLTK Downloader sẽ hiện ra </p>
	<p class="block_9"><img alt="Image" src="images/000000.png" class="calibre3" /></p>
	<p class="block_1">Chọn AllPackage, chọn đường dẫn tới nơi cần download Ctrl+A để chọn hết -sau đó bấm nút Download.</p>
	<p class="block_1">Để đường dẫn Download Directory là default sẽ vào RoamingData còn nếu bạn muốn download vào thư mục xác định thì phải chỉnh đường dẫn cho nltk biết source data nằm ở đâu như sau:</p>
	<div class="frame_"><p class="block_10"><span class="text_">import </span><span class="text_1">nltk<br class="calibre4" />nltk.data.path.append(</span><span class="text_2">"D:</span><span class="text_">\\</span><span class="text_2">PycharmProjects</span><span class="text_">\\</span><span class="text_2">AILearn</span><span class="text_">\\</span><span class="text_2">NLTK"</span><span class="text_1">)</span></p><p class="block_11"></p></div>
	<p class="block_12"><span class="text_3">Hoặc chỉnh path cho Environtment nếu ban dùng windows:</span><span class="text_4"> &nbsp;NLTK_DATA = Path to Data</span></p>
	<p class="block_1">Ngoài ra chúng ta cũng cần dùng thêm một vài thư viện nữa</p>
	<ul class="list_">
	<li class="block_2"><i class="calibre5">gensim: </i>Mô hình về ngữ nghĩa mạnh và hữu ích được dùng cho nhiều ứng dụng</li>
	<li class="block_4"><i class="calibre5">pattern:</i> là một thư viện giúp cho <i class="calibre5">gensim</i> làm việc hiệu quả hơn.</li>
</ul>
	<p class="block_1"><a class="text_5" href="http://www.nltk.org">http://www.nltk.org</a></p>
	<p class="block_1"><a class="text_5" href="https://radimrehurek.com/gensim/">https://radimrehurek.com/gensim/</a></p>
	<p class="block_5">Phân tách chuỗi dữ liệu văn bản(Tokenizing)</p>
	<p class="block_1">Khi chúng ta làm việc với văn bản chúng ta cần phải cắt chúng thành những đoạn ngắn hơn để phân tích. Đây là lúc mà chúng ta cần tìm hiểu về Tokenizing. Nó là quá trính sử lý phân chia văn bản được nhập vào thành một bộ những mảnh nhỏ như là từ, hoặc câu. Những mảnh nhỏ này được gọi là tokens. Dựa trên những gì chúng ta muốn làm chúng ta có thể định nghĩa những hàm chia văn bản thành bao nhiêu tokens. Giờ ta dùng thư viện NLTK đã cài đặt để phân tách chuỗi dữ liệu.</p>
	<div class="frame_"><p class="block_10"><span class="text_">import </span><span class="text_2">nltk<br class="calibre4" />nltk.data.path.append(</span><span class="text_6">"D:</span><span class="text_">\\</span><span class="text_6">PycharmProjects</span><span class="text_">\\</span><span class="text_6">AILearn</span><span class="text_">\\</span><span class="text_6">NLTK"</span><span class="text_2">)<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.tokenize </span><span class="text_">import </span><span class="text_2">sent_tokenize</span><span class="text_">,</span><span class="text_2">word_tokenize</span><span class="text_">,</span><span class="text_2">WordPunctTokenizer<br class="calibre4" /></span><span class="text_7"># Tạo một đoạn văn bản input để sử dụng tokenization<br class="calibre4" /></span><span class="text_2">input_text=</span><span class="text_6">"Hôm nay trời đẹp, 25* C. Chúng ta nên đi ra ngoài chơi. Hôm qua trời mưa tao ở nhà ngủ. Còn mày có đi chơi không ?"<br class="calibre4" /></span><span class="text_7"># Chia đoạn trên thành các câu tokens<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"</span><span class="text_">\n</span><span class="text_6">Chuyển đoạn văn thành câu:"</span><span class="text_2">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(sent_tokenize(input_text))<br class="calibre4" /></span><span class="text_7"># Chia đoạn trên thành các từ<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"</span><span class="text_">\n</span><span class="text_6">Chuyển đoạn trên thành các từ"</span><span class="text_2">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(word_tokenize(input_text))<br class="calibre4" /></span><span class="text_7"># Chia đoạn trên thành các từ sử dụng hàm Word Punct Token<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"Token by WordPunctToken"</span><span class="text_2">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(WordPunctTokenizer().tokenize(input_text))</span></p><p class="block_11"></p></div>
	<p class="block_1">Kết quả:</p>
	<p class="block_6">Chuyển đoạn văn thành câu:</p>
	<p class="block_7">['Hôm nay trời đẹp, 25* C. Chúng ta nên đi ra ngoài chơi.', 'Hôm qua trời mưa tao ở nhà ngủ.', 'Còn mày có đi chơi không ?']</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Chuyển đoạn trên thành các từ</p>
	<p class="block_7">['Hôm', 'nay', 'trời', 'đẹp', ',', '25*', 'C.', 'Chúng', 'ta', 'nên', 'đi', 'ra', 'ngoài', 'chơi', '.', 'Hôm', 'qua', 'trời', 'mưa', 'tao', 'ở', 'nhà', 'ngủ', '.', 'Còn', 'mày', 'có', 'đi', 'chơi', 'không', '?']</p>
	<p class="block_7">Token by WordPunctToken</p>
	<p class="block_7">['Hôm', 'nay', 'trời', 'đẹp', ',', '25', '*', 'C', '.', 'Chúng', 'ta', 'nên', 'đi', 'ra', 'ngoài', 'chơi', '.', 'Hôm', 'qua', 'trời', 'mưa', 'tao', 'ở', 'nhà', 'ngủ', '.', 'Còn', 'mày', 'có', </p>
	<p class="block_8">'đi', 'chơi', 'không', '?']</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_5">Chuyển đồi Từ thành dạng cơ bản của chúng sử dụng stemming</p>
	<p class="block_1">Làm việc với văn bản chúng ta sẽ gặp rất nhiều biến thể bao gồm trong đó. Chúng ta phải xem xét các dạng khác nhau của từ để làm cho máy tính hiểu đó là những từ khác nhau đó có cùng dạng cơ bản. Ví dụ từ sing trong tiếng anh có rất nhiều biến thể giống như sang, singer, singing, và những từ kiểu như thế rất nhiều. Chúng ta thấy đó là một tập hợp các từ có ý nghĩa tương tượng. Con người có thể dễ dàng nhận ra điều đó nhờ bối cảnh.</p>
	<p class="block_1">Khi chúng ta phân tích văn bản, sẽ hữu dụng hơn nếu chúng ta tách nó thành dạng cơ bản. Nó sẽ giúp chúng ta phân tách số liệu hữu ích để phân tích văn bản input. Stemming là một cách để làm điều đó. Mục đích của một bộ Chuyển đổi Stemmer là giảm số lượng từ nhờ biến đổi những định dạng khác nhau của chúng thành dạng cơ bản. Nó cơ bản là quá trình xử lý heuristic nó sẽ bỏ các giá trị tiền tố (un-happy) hoặc hậu tố (happi-ness) của từ để biến nó thành dạng cơ bản ( điều này méo có giá trị trong tiếng Việt). </p>
	<div class="frame_"><p class="block_10"><span class="text_">import </span><span class="text_2">nltk<br class="calibre4" />nltk.data.path.append(</span><span class="text_6">"D:</span><span class="text_">\\</span><span class="text_6">PycharmProjects</span><span class="text_">\\</span><span class="text_6">AILearn</span><span class="text_">\\</span><span class="text_6">NLTK"</span><span class="text_2">)<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.stem.porter </span><span class="text_">import </span><span class="text_2">PorterStemmer<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.stem.lancaster </span><span class="text_">import </span><span class="text_2">LancasterStemmer<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.stem.snowball </span><span class="text_">import </span><span class="text_2">SnowballStemmer<br class="calibre4" /><br class="calibre4" />input_words=[</span><span class="text_6">'writing'</span><span class="text_">, </span><span class="text_6">'calves'</span><span class="text_">, </span><span class="text_6">'be'</span><span class="text_">, </span><span class="text_6">'branded'</span><span class="text_">, </span><span class="text_6">'horse'</span><span class="text_">, </span><span class="text_6">'randomize'</span><span class="text_">, </span><span class="text_6">'possibly'</span><span class="text_">, </span><span class="text_6">'provision'</span><span class="text_">, </span><span class="text_6">'hospital'</span><span class="text_">, </span><span class="text_6">'kept'</span><span class="text_">, </span><span class="text_6">'scratchy'</span><span class="text_">, </span><span class="text_6">'code'</span><span class="text_2">]<br class="calibre4" />porter=PorterStemmer()<br class="calibre4" />lancaster=LancasterStemmer()<br class="calibre4" />snowball=SnowballStemmer(</span><span class="text_6">'english'</span><span class="text_2">)<br class="calibre4" /></span><span class="text_7">#Tạo list tên stemmer để hiển thị ra màn hình<br class="calibre4" /></span><span class="text_2">stemmer_names=[</span><span class="text_6">'Porter'</span><span class="text_">,</span><span class="text_6">'Lancaster'</span><span class="text_">,</span><span class="text_6">'Snowball'</span><span class="text_2">]<br class="calibre4" />formatted_text = </span><span class="text_6">'{:&gt;16}' </span><span class="text_2">* (</span><span class="text_8">len</span><span class="text_2">(stemmer_names) + </span><span class="text_9">1</span><span class="text_2">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">'</span><span class="text_">\n</span><span class="text_6">'</span><span class="text_">, </span><span class="text_2">formatted_text.format(</span><span class="text_6">'INPUT WORD'</span><span class="text_">, </span><span class="text_2">*stemmer_names)</span><span class="text_">, </span><span class="text_6">'</span><span class="text_">\n</span><span class="text_6">'</span><span class="text_">, </span><span class="text_6">'='</span><span class="text_2">*</span><span class="text_9">68</span><span class="text_2">)<br class="calibre4" /></span><span class="text_7"># Tạo vòng lặp để stem các từ sử dụng 3 stemmer:<br class="calibre4" /></span><span class="text_">for </span><span class="text_2">word </span><span class="text_">in </span><span class="text_2">input_words:<br class="calibre4" /><span class="calibre6">    output = [word</span></span><span class="text_">, </span><span class="text_2">porter.stem(word)</span><span class="text_">, </span><span class="text_2">lancaster.stem(word)</span><span class="text_">, </span><span class="text_2">snowball.stem(word)]<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_8">print</span><span class="text_2">(formatted_text.format(*output))</span></p><p class="block_11"></p></div>
	<p class="block_1">Kết quả:</p>
	<p class="block_6"><span class="calibre6">       INPUT WORD          Porter       Lancaster        Snowball </span></p>
	<p class="block_7"> ====================================================================</p>
	<p class="block_7"><span class="calibre6">         writing           write            writ           write</span></p>
	<p class="block_7"><span class="calibre6">          calves            calv            calv            calv</span></p>
	<p class="block_7"><span class="calibre6">              be              be              be              be</span></p>
	<p class="block_7"><span class="calibre6">         branded           brand           brand           brand</span></p>
	<p class="block_7"><span class="calibre6">           horse            hors            hors            hors</span></p>
	<p class="block_7"><span class="calibre6">       randomize          random          random          random</span></p>
	<p class="block_7"><span class="calibre6">        possibly         possibl            poss         possibl</span></p>
	<p class="block_7"><span class="calibre6">       provision          provis          provid          provis</span></p>
	<p class="block_7"><span class="calibre6">        hospital          hospit          hospit          hospit</span></p>
	<p class="block_7"><span class="calibre6">            kept            kept            kept            kept</span></p>
	<p class="block_7"><span class="calibre6">        scratchy        scratchi        scratchy        scratchi</span></p>
	<p class="block_8"><span class="calibre6">           code            code             cod            code</span></p>
	<p class="block_1">Hãy nói một chút về 3 thuật toán stemming đã dùng ở đây. Về cơ bản thì nó đều cố gắng để steam từ thành dạng cơ bản. Các khác giữa 3 thuật toán này là mức độ quản lý từ được dùng để chuyển đổi thành dạng cơ bản. </p>
	<p class="block_1">Porter là cái quản lý ít nghiêm ngặt nhất ngược lại là Landcaster. Nếu bạn nhìn vào kết quả output bạn sẽ thấy điều khác nhau khi xử lý cùng một từ. Vd nhìn vào Input_word là <i class="calibre5">possibibly</i> Porter ra kết quả là possibl và Landcaster là poss. Kết quả của Landcasster có vấn đề một chút vì nó giảm lượng từ quá nhiều. Nếu tính về thời gian sử lý thì Landcaster nhanh hơn và lựa chọn tối ưu cho vấn đề này là dùng Snowball. Nó được lợi cả về thời gian sử lý và mức độ ngắt từ.</p>
	<p class="block_5">Chuyển đổi từ về dạng cơ bản của nó sử dụng lemmatization</p>
	<p class="block_1"><b class="calibre2">Lemmatization</b> là một cách khác để chuyển đổi từ về dạng cơ bản. Trong phần trước chúng ta thấy từ cơ bản được chuyển thể từ steamer có vẻ không được ổn cho lắm. Ví dụ nó chuyển từ </p>
	<p class="block_1"><i class="calibre5">calves</i>- từ này có nhiều nghĩa như bò con,da bò , khờ khạo….xx.t lại chuyển thành calv gần như ko có nghĩa, cái này không đúng với thực tế. Lemmatization có thể giải quyết được vấn đề này:</p>
	<p class="block_14"><span class="text_">import </span><span class="text_1">nltk<br class="calibre4" />nltk.data.path.append(</span><span class="text_2">"D:</span><span class="text_">\\</span><span class="text_2">PycharmProjects</span><span class="text_">\\</span><span class="text_2">AILearn</span><span class="text_">\\</span><span class="text_2">NLTK"</span><span class="text_1">)<br class="calibre4" /></span><span class="text_">from </span><span class="text_1">nltk.stem </span><span class="text_">import </span><span class="text_1">WordNetLemmatizer<br class="calibre4" />input_words=[</span><span class="text_2">'writing'</span><span class="text_">, </span><span class="text_2">'calves'</span><span class="text_">, </span><span class="text_2">'be'</span><span class="text_">, </span><span class="text_2">'branded'</span><span class="text_">, </span><span class="text_2">'horse'</span><span class="text_">, </span><span class="text_2">'randomize'</span><span class="text_">, </span><span class="text_2">'possibly'</span><span class="text_">, </span><span class="text_2">'provision'</span><span class="text_">, </span><span class="text_2">'hospital'</span><span class="text_">, </span><span class="text_2">'kept'</span><span class="text_">, </span><span class="text_2">'scratchy'</span><span class="text_">, </span><span class="text_2">'code'</span><span class="text_1">]<br class="calibre4" />lemmatizer=WordNetLemmatizer()<br class="calibre4" />lemmatizer_names = [</span><span class="text_2">'NOUN LEMMATIZER'</span><span class="text_">, </span><span class="text_2">'VERB LEMMATIZER'</span><span class="text_1">]<br class="calibre4" />formatted_text = </span><span class="text_2">'{:&gt;24}' </span><span class="text_1">* (</span><span class="text_8">len</span><span class="text_1">(lemmatizer_names) + </span><span class="text_9">1</span><span class="text_1">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_1">(</span><span class="text_2">'</span><span class="text_">\n</span><span class="text_2">'</span><span class="text_">, </span><span class="text_1">formatted_text.format(</span><span class="text_2">'INPUT WORD'</span><span class="text_">, </span><span class="text_1">*lemmatizer_names)</span><span class="text_">, </span><span class="text_2">'</span><span class="text_">\n</span><span class="text_2">'</span><span class="text_">, </span><span class="text_2">'='</span><span class="text_1">*</span><span class="text_9">75</span><span class="text_1">)<br class="calibre4" /></span><span class="text_">for </span><span class="text_1">word </span><span class="text_">in </span><span class="text_1">input_words:<br class="calibre4" /><span class="calibre6">    output = [word</span></span><span class="text_">, </span><span class="text_1">lemmatizer.lemmatize(word</span><span class="text_">, </span><span class="text_10">pos</span><span class="text_1">=</span><span class="text_2">'n'</span><span class="text_1">)</span><span class="text_">,<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_1">lemmatizer.lemmatize(word</span><span class="text_">, </span><span class="text_10">pos</span><span class="text_1">=</span><span class="text_2">'v'</span><span class="text_1">)]<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_8">print</span><span class="text_1">(formatted_text.format(*output))</span></p>
	<p class="block_1">Kết quả</p>
	<p class="block_6"><span class="calibre6">INPUT WORD         NOUN LEMMATIZER         VERB LEMMATIZER </span></p>
	<p class="block_7"> ===================================================================</p>
	<p class="block_7"><span class="calibre6">writing                 writing                   write</span></p>
	<p class="block_7"><span class="calibre6">calves                    calf                   calve</span></p>
	<p class="block_7"><span class="calibre6">be                      be                      be</span></p>
	<p class="block_7"><span class="calibre6">branded                 branded                   brand</span></p>
	<p class="block_7"><span class="calibre6">horse                   horse                   horse</span></p>
	<p class="block_7"><span class="calibre6">randomize               randomize               randomize</span></p>
	<p class="block_7"><span class="calibre6">possibly                possibly                possibly</span></p>
	<p class="block_7"><span class="calibre6">provision               provision               provision</span></p>
	<p class="block_7"><span class="calibre6">hospital                hospital                hospital</span></p>
	<p class="block_7"><span class="calibre6">kept                    kept                    keep</span></p>
	<p class="block_7"><span class="calibre6">scratchy                scratchy                scratchy</span></p>
	<p class="block_8"><span class="calibre6">code                    code                    code</span></p>
	<p class="block_1">Nhìn vào kết quả của 2 phép chuyển đổi (steamer và lemmatizer) bạn đã hiểu chúng khác nhau thế nào chưa. Chưa hiểu thì đọc lại nhé.</p>
	<p class="block_5">Chia dữ liệu văn bản thành các đoạn nhỏ</p>
	<p class="block_1">Văn bản dữ liệu thường cần phải được chia thành các mảnh nhỏ để dễ phân tích. Quá trình xử lý này được gọi là <i class="calibre5">chunking</i>. Nó thường được dùng để phân tích văn bản. Các điều kiện được sử dụng để phân chia văng bản thành các đoạn nhỏ dựa trên những vấn đề chúng ta đang có trong tay. Trong quá trình phân chia (chunking), chúng ta không cần phải tuân thủ ràng buộc nào là kết quả đầu ra phải là những đoạn có ý nghĩa.</p>
	<p class="block_1">Khi chúng ta gặp phải những tài liệu văn bản lớn, điều này sẽ rất quan trọng để chia những văn bản thành những đoạn nhỏ thông tin chính xác.Trong phần này, chúng ta sẽ xem cách nào để chia những đoạn văn bản thành từng mảnh.</p>
	<div class="frame_"><p class="block_10"><span class="text_2"># Tạo hàm chunk để chia dữ liệu input thành những đoạn nhỏ. Tham số đầu tiên là input text và tham số thứ 2 là số từ trong mỗi đoạn<br class="calibre4" /></span><span class="text_">def </span><span class="text_11">chunker</span><span class="text_1">(input_data</span><span class="text_">,</span><span class="text_1">N):<br class="calibre4" /><span class="calibre6">    input_words=input_data.split(</span></span><span class="text_6">' '</span><span class="text_1">)<br class="calibre4" /><span class="calibre6">    output=[]</span></span><span class="text_1"><br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2"># Lặp tất cả văn bản để chia chúng vào từng đoạn<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_1">cur_chunk=[]<br class="calibre4" /><span class="calibre6">    count=</span></span><span class="text_9">0<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">for </span><span class="text_1">word </span><span class="text_">in </span><span class="text_1">input_words:<br class="calibre4" /><span class="calibre6">        cur_chunk.append(word)</span></span><span class="text_1"><br class="calibre4" /><span class="calibre6">        count+=</span></span><span class="text_9">1<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_">if </span><span class="text_1">count==N:<br class="calibre4" /><span class="calibre6">            output.append(</span></span><span class="text_6">' '</span><span class="text_1">.join(cur_chunk))<br class="calibre4" /><span class="calibre6">            count</span></span><span class="text_">,</span><span class="text_1">cur_chunk=</span><span class="text_9">0</span><span class="text_">,</span><span class="text_1">[]<br class="calibre4" /><span class="calibre6">    output.append(</span></span><span class="text_6">' '</span><span class="text_1">.join(cur_chunk))<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">return </span><span class="text_1">output<br class="calibre4" /></span><span class="text_">def </span><span class="text_11">inputTxt</span><span class="text_1">():<br class="calibre4" /><span class="calibre6">    input_file = </span></span><span class="text_8">open</span><span class="text_1">(</span><span class="text_6">"data/chap10/doaremon.txt"</span><span class="text_">, </span><span class="text_6">'r'</span><span class="text_">, </span><span class="text_10">encoding</span><span class="text_1">=</span><span class="text_6">'utf-8'</span><span class="text_1">)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2"># Loại bỏ các dòng<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_1">input_string = input_file.read().splitlines()<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2"># Join array lại thành string<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_1">input_string=</span><span class="text_6">" "</span><span class="text_1">.join(input_string)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">return </span><span class="text_1">input_string<br class="calibre4" /></span><span class="text_">if </span><span class="text_1">__name__==</span><span class="text_6">"__main__"</span><span class="text_1">:<br class="calibre4" /><span class="calibre6">    chunk_size = </span></span><span class="text_9">100<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_1">chunks=chunker(inputTxt()</span><span class="text_">,</span><span class="text_1">chunk_size)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_8">print</span><span class="text_1">(</span><span class="text_6">'</span><span class="text_">\n</span><span class="text_6">Số mảnh trong đoạn văn ='</span><span class="text_">,</span><span class="text_8">len</span><span class="text_1">(chunks)</span><span class="text_">,</span><span class="text_6">'</span><span class="text_">\n</span><span class="text_6">'</span><span class="text_1">)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">for </span><span class="text_1">i</span><span class="text_">,</span><span class="text_1">chunk </span><span class="text_">in </span><span class="text_8">enumerate</span><span class="text_1">(chunks):<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_8">print</span><span class="text_1">(</span><span class="text_6">"Đoạn"</span><span class="text_">,</span><span class="text_1">i+</span><span class="text_9">1</span><span class="text_">,</span><span class="text_6">'==&gt;'</span><span class="text_">,</span><span class="text_1">chunk[:</span><span class="text_9">50</span><span class="text_1">])</span></p><p class="block_11"></p></div>
	<p class="block_1">Kết quả:</p>
	<p class="block_15">&nbsp;</p>
	<p class="block_7">Số mảnh trong đoạn văn = 10 </p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Đoạn 1 ==&gt; Mới đọc lại Doraemon và nhận ra một số thứ.Cả 5 đứ</p>
	<p class="block_7">Đoạn 2 ==&gt; kì lâu đời, toàn trai phố, gái phố. Đám này khác v</p>
	<p class="block_7">Đoạn 3 ==&gt; ra cái hỏng hết, đắt ở đất chứ nhà không ở được, t</p>
	<p class="block_7">Đoạn 4 ==&gt; không nghèo. Nhà mặt tiền đất trung tâm phố cổ Tok</p>
	<p class="block_7">Đoạn 5 ==&gt; tược đàng hoàng. Nhà còn mua hẳn piano, violin cho</p>
	<p class="block_7">Đoạn 6 ==&gt; kề ở khắp nơi, thường xuyên cho con đi du lịch, ch</p>
	<p class="block_7">Đoạn 7 ==&gt; đồ họa, công trình, lắp ráp robot, cơ khí các kiểu</p>
	<p class="block_7">Đoạn 8 ==&gt; anh thế phiệt, con quan chức, chính khách, không c</p>
	<p class="block_7">Đoạn 9 ==&gt; cũng biết, giỏi toàn năng, chuẩn con nhà người ta </p>
	<p class="block_8">Đoạn 10 ==&gt; bù trừ thì có thể Dekhi là bê đê, bóng kín không t</p>
	<p class="block_5">Trích xuất tần số thuất hiện sử dụng mô hình Bag of Words</p>
	<p class="block_1">Một trong những mục đích chính của phân tích văn bản là chuyển đổi văn bản thành số (số hóa dữ liệu) và chúng ta có thể sử dụng ML để làm việc này. Hãy xem xét một tài liệu văn bản chứa cả triệu từ . Để giải phân tích văn bản này, chúng ta cần phải phân tách văn bản và chuyển đổi nó thành dạng số hóa. </p>
	<p class="block_1">Thuật toán ML cần ở dạng số để làm việc để chúng có thể phân tích dữ liệu và trích xuất thông tin hữu ích. Đây là lúc chúng ta lôi mô hình Bag of Words ra để sử dụng. Mô hình trich xuất này trích xuất một từ vựng từ tất cả các từ có trong tài liệu và xây dựng một mô hình sử dụng ma trận thuật ngữ tài liệu. Nó cho phép chúng ta miêu tả mọi tài liệu thành <i class="calibre5">bag of words. (Vietnamese gọi là túi khôn)</i>. Chúng ta theo dõi số lượng từ và bỏ qua chi tiết về ngữ pháp và vị trí các từ.</p>
	<p class="block_1"><b class="calibre2">Ma trận thuật ngữ tài liệu:</b> (document-term matrix). Là một bảng cung cấp cho chúng ta số lượng từ khác nhau xảy ra trong tài liệu. Vì vậy một tài liệu văn bản có thể biểu diễn dưới dạng kết hợp số lượng của các từ khác nhau. Chúng ta có thể đặt ngưỡng và chọn những từ có ý nghĩa hơn. Theo một cách nào đó chúng ta đang xây dựng một biểu đồ của tất cả các từ trong tài liệu sẽ được sử dụng như một vector tính năng. Vector tính năng này được sử dụng để phân loại văn bản.</p>
	<p class="block_1">Xét những câu sau:</p>
	<ul class="list_">
	<li class="block_2">Câu 1: Đứa trẻ đang chơi ở trong sân </li>
	<li class="block_3">Câu 2: Con bò đang ăn cỏ ở trong cánh đồng</li>
	<li class="block_4">Câu 3: Nhiều đứa trẻ đang chơi ở trong khu thể thao</li>
</ul>
	<p class="block_1">Nếu bạn xem xét cả 3 câu trên thì bạn sẽ thấy nó gồm 17 từ sau:</p>
	<ol class="list_1">
	<li class="block_2">đứa <span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">trẻ <span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">đang </li>
	<li class="block_3">chơi <span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">ở <span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">trong <span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">sân <span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">con <span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">bò <span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">ăn<span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span> </li>
	<li class="block_3">cỏ<span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">cánh<span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">đồng<span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">nhiều<span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">khu<span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_3">thể<span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
	<li class="block_4">thao<span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li>
</ol>
	<p class="block_1">Có 17 từ riêng biệt ở đây và giờ ta sẽ xây dựng lại biểu đồ của mỗi câu dựa trên số lượng từ ở mỗi câu. Mỗi vector tính năng sẽ có 17 cột bởi vì chúng ta có 17 từ riêng biệt tất cả.</p>
	<ul class="list_">
	<li class="block_2">Câu 1: [1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0]</li>
	<li class="block_3">Câu 2:[0,0,1,0,1,1,0,1,1,1,1,1,1,0,0,0,0]</li>
	<li class="block_4">Câu 3:[ 1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1]</li>
</ul>
	<p class="block_1">Ta đánh dấu các vị trí xuất hiện của các từ và diễn tả lại câu theo dạng vector tính năng. Vì có tất cả 17 từ nên ta sẽ tạo 1 vector 17 cột từ đó xuất hiện ở vị trí bao nhiêu trên bảng xếp hạng trên cùng thì ta sẽ đánh dấu số "1" vào đó. Nếu trong câu xuất hiện 1 từ 2 lần thì sẽ đánh dấu số "2". Giờ thì ta đã xong công việc "số hóa" tài liệu và có thể dùng thuật toán ML để phân tích dữ liệu</p>
	<p class="block_1">Giờ ta thử xây dựng mô hình "Túi khôn" Bag of Words bằng NLTK.</p>
	<div class="frame_"><p class="block_10"><span class="text_">import </span><span class="text_2">numpy </span><span class="text_">as </span><span class="text_2">np<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">sklearn.feature_extraction.text </span><span class="text_">import </span><span class="text_2">CountVectorizer<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">chunks_text </span><span class="text_">import </span><span class="text_2">chunker</span><span class="text_">,</span><span class="text_2">inputTxt<br class="calibre4" /><br class="calibre4" /></span><span class="text_7"># Tạo cỡ đoạn văn<br class="calibre4" /></span><span class="text_2">chunk_size=</span><span class="text_9">200<br class="calibre4" /></span><span class="text_7"># Chia text thành các đoạn văn:<br class="calibre4" /></span><span class="text_2">text_chunk=chunker(inputTxt()</span><span class="text_">,</span><span class="text_2">chunk_size)<br class="calibre4" />chunks=[]<br class="calibre4" /></span><span class="text_">for </span><span class="text_2">count</span><span class="text_">,</span><span class="text_2">chunk </span><span class="text_">in </span><span class="text_8">enumerate</span><span class="text_2">(text_chunk):<br class="calibre4" /><span class="calibre6">    d={</span></span><span class="text_6">'index'</span><span class="text_2">:count</span><span class="text_">,</span><span class="text_6">'text'</span><span class="text_2">:chunk}<br class="calibre4" /><span class="calibre6">    chunks.append(d)</span></span><span class="text_2"><br class="calibre4" /></span><span class="text_7"># Ta sử dụng hàm CountVectorizer đề đếm số lượng từ và biến đổi chúng thành ma trận số hóa<br class="calibre4" /></span><span class="text_2">countvectorizer=CountVectorizer(</span><span class="text_10">min_df</span><span class="text_2">=</span><span class="text_9">5</span><span class="text_">,</span><span class="text_10">max_df</span><span class="text_2">=</span><span class="text_9">20</span><span class="text_2">)<br class="calibre4" /></span><span class="text_7">#print(chunks)<br class="calibre4" /></span><span class="text_2">document_termatrix=countvectorizer.fit_transform(chunk[</span><span class="text_6">'text'</span><span class="text_2">] </span><span class="text_">for </span><span class="text_2">chunk </span><span class="text_">in </span><span class="text_2">chunks)<br class="calibre4" />vocalbulary=np.array(countvectorizer.get_feature_names())<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"</span><span class="text_">\n</span><span class="text_6">Volcabulary</span><span class="text_">\n</span><span class="text_6">"</span><span class="text_">,</span><span class="text_2">vocalbulary)<br class="calibre4" /></span><span class="text_">for </span><span class="text_2">i</span><span class="text_">,</span><span class="text_2">chunk </span><span class="text_">in </span><span class="text_8">enumerate</span><span class="text_2">(text_chunk):<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"Đoạn"</span><span class="text_">,</span><span class="text_2">i+</span><span class="text_9">1</span><span class="text_">,</span><span class="text_6">'==&gt;'</span><span class="text_">,</span><span class="text_2">chunk[:</span><span class="text_9">50</span><span class="text_2">])<br class="calibre4" />chunk_names = []<br class="calibre4" /></span><span class="text_">for </span><span class="text_2">i </span><span class="text_">in </span><span class="text_8">range</span><span class="text_2">(</span><span class="text_8">len</span><span class="text_2">(text_chunk)):<br class="calibre4" /><span class="calibre6">    chunk_names.append(</span></span><span class="text_6">'Đoạn-' </span><span class="text_2">+ </span><span class="text_8">str</span><span class="text_2">(i+</span><span class="text_9">1</span><span class="text_2">))<br class="calibre4" /></span><span class="text_7"># Print the document term matrix<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"</span><span class="text_">\n</span><span class="text_6">Document term matrix:"</span><span class="text_2">)<br class="calibre4" />formatted_text = </span><span class="text_6">'{:&gt;12}' </span><span class="text_2">* (</span><span class="text_8">len</span><span class="text_2">(chunk_names) + </span><span class="text_9">1</span><span class="text_2">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">'</span><span class="text_">\n</span><span class="text_6">'</span><span class="text_">, </span><span class="text_2">formatted_text.format(</span><span class="text_6">'Word'</span><span class="text_">, </span><span class="text_2">*chunk_names)</span><span class="text_">, </span><span class="text_6">'</span><span class="text_">\n</span><span class="text_6">'</span><span class="text_2">)<br class="calibre4" /></span><span class="text_">for </span><span class="text_2">word</span><span class="text_">, </span><span class="text_2">item </span><span class="text_">in </span><span class="text_8">zip</span><span class="text_2">(vocalbulary</span><span class="text_">, </span><span class="text_2">document_termatrix.T):<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># 'item' is a 'csr_matrix' data structure<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">output = [word] + [</span><span class="text_8">str</span><span class="text_2">(freq) </span><span class="text_">for </span><span class="text_2">freq </span><span class="text_">in </span><span class="text_2">item.data]<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_8">print</span><span class="text_2">(formatted_text.format(*output))</span></p><p class="block_11"></p></div>
	<p class="block_1">Kết quả:</p>
	<p class="block_6">Volcabulary</p>
	<p class="block_7"> ['con' 'có' 'cũng' 'không' 'kiểu' 'làm' 'nhà' 'nobita']</p>
	<p class="block_7">Đoạn 1 ==&gt; Mới đọc lại Doraemon và nhận ra một số thứ.Cả 5 đứ</p>
	<p class="block_7">Đoạn 2 ==&gt; ra cái hỏng hết, đắt ở đất chứ nhà không ở được, t</p>
	<p class="block_7">Đoạn 3 ==&gt; tược đàng hoàng. Nhà còn mua hẳn piano, violin cho</p>
	<p class="block_7">Đoạn 4 ==&gt; đồ họa, công trình, lắp ráp robot, cơ khí các kiểu</p>
	<p class="block_7">Đoạn 5 ==&gt; cũng biết, giỏi toàn năng, chuẩn con nhà người ta </p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Document term matrix:</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7"><span class="calibre6">         Word      Đoạn-1      Đoạn-2      Đoạn-3      Đoạn-4      Đoạn-5 </span></p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7"><span class="calibre6">         con           1           2           3           2           2</span></p>
	<p class="block_7"><span class="calibre6">          có           2           4           4           4           5</span></p>
	<p class="block_7"><span class="calibre6">        cũng           2           1           2           1           2</span></p>
	<p class="block_7"><span class="calibre6">       không           2           5           3           4           6</span></p>
	<p class="block_7"><span class="calibre6">        kiểu           3           1           2           4           1</span></p>
	<p class="block_7"><span class="calibre6">         làm           1           1           1           1           2</span></p>
	<p class="block_7"><span class="calibre6">         nhà           6           7           6           4           2</span></p>
	<p class="block_8"><span class="calibre6">      nobita           3           2           1           2           6</span></p>
	<p class="block_5">Xây dựng một bộ phân loại thể loại văn bản</p>
	<p class="block_1">Một bộ dự đoán thể loại văn bản được sử dụng để phân loại thể loại văn bản được nhập vào. Nó thường được sử dụng trong phân loại văn bản thành các thể loại tài liệu. Các bộ máy tìm kiếm cũng thường dùng ứng dụng này để xắp xếp kết quả tìm kiếm liên quan. Ví dụ chúng ta muốn dự đoán xem câu được người dùng đưa ra thuộc thể loại thể thao, chính trị, hay khoa học. Để làm điều này chúng ta xây dựng một tập dữ liệu và đào tạo một thuật toán (train an algorithm). Thuật toán này có thể sử dụng để suy luận (inference) trên một dữ liệu không biết.</p>
	<p class="block_1">Để xây dựng bộ phân loại này, chúng ta sử dụng một thống kê được gọi là <b class="calibre2">( TermFrequency-Inverse document Frequency(tf-idf) &ndash;tf:tạm dịch là tần suất của một từ trong văn bản &ndash; idf tần suất nghich của 1 từ trong văn bản ) </b><span class="calibre1">. Trong một bộ tài liệu, chúng ta cần phải hiểu tầm quan trọng của mỗi từ.  Thống kê tf-idf</span> giúp chúng ta hiểu tầm quan trọng của một từ trong một văn bản và trong một tập văn bản. </p>
	<p class="block_1">Hãy xem thử phần đầu của thông số này được gọi là<b class="calibre2"> TF(TermFrequency)</b>: Cơ bản nó là tần số xuất hiện (tần suất) của mỗi từ xuất hiện trong văn bản. Từ những văn bản khác nhau có những số khác nhau, những số này trong biểu đồ sẽ thay đổi. Để cân bằng chúng ta phải đơn giản hóa (normalize) những biểu đò. Vì vậy chúng ta phải chia những bộ đếm cho mỗi từ với tổng số từ có trong tài liệu để lấy được tần suất (term frequency).</p>
	<p class="block_1"><b class="calibre2">Inverse document Frequency: </b> là số đo lường của từ đó có ý nghĩa thế nào với văn bản. Khi chúng ta tính toán số tần suất , giả sử tất cả các từ đều quan trọng. Nhưng chúng ta không thể để chỉ dựa vào tần suất này ( vd từ: và, nó, cái ) có thể xuất hiện rất nhiều lần. Để cân bằng tuần suất của những từ thông dụng này, chúng ta cần phải giảm mức độ quan trọng của chúng và tăng mức độ quan trọng của những từ hiếm gặp hoặc đặc biệt. Điều này giúp chúng ta nhận dạng được những từ đặc biệt quan trọng đối với văn bản, giúp chúng ta xây dựng được một vector đặc trưng (feature vector).</p>
	<p class="block_1"><span class="calibre1">Để tính toán thống kê này chúng ta cần tính tỉ lệ số lượng của tài liệu với số từ đã cho và chia nó với tổng số từ có trong tài liệu. Tỉ lệ này thực chất là một phần của văn bản bao gồm cả các từ đã cho. Tần suất nghịc đảo (idf) sau đó được tính bằng cách lấy giá trị âm của tỉ  lệ này </span></p>
	<p class="block_1">Khi chúng ta kết hợp 2 chỉ số đo lường TF-idf chúng ta có một công thức để tính vector tính năng cho phân loại thể loại tài liệu. </p>
	<p class="block_1">Những từ có giá trị TF-idf cao là những từ xuất hiện nhiều trong tài liệu này và ít xuất hiện trong tài liệu khác (dựa vào các tài liệu đã train), sẽ giúp chúng ta lọc bỏ ra những từ phổ biến và giữ lại những từ có giá trị - đây là những từ khóa cho tài liệu đó.</p>
	<p class="block_12">&nbsp;</p>
	<div class="frame_"><p class="block_10"><span class="text_">from </span><span class="text_2">sklearn.datasets </span><span class="text_">import </span><span class="text_2">load_files<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">sklearn.naive_bayes </span><span class="text_">import </span><span class="text_2">MultinomialNB<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">sklearn.feature_extraction.text </span><span class="text_">import </span><span class="text_2">TfidfTransformer<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">sklearn.feature_extraction.text </span><span class="text_">import </span><span class="text_2">CountVectorizer<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">sklearn.pipeline </span><span class="text_">import </span><span class="text_2">Pipeline<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">sklearn.linear_model </span><span class="text_">import </span><span class="text_2">SGDClassifier<br class="calibre4" /><br class="calibre4" /></span><span class="text_7"># Lấy data từ dữ liệu có sẵn ở đây tôi dùng thư viện của VNTC đã tổng hợp từ các trang báo và phân loại sẵn theo thư mục.<br class="calibre4" /><span class="calibre6"># Dữ liệu ở  https://github.com/duyvuleo/VNTC/</span></span><span class="text_7"><br class="calibre4" /></span><span class="text_2">train_path=</span><span class="text_6">"data/chap10/Categories_documents/Train/"<br class="calibre4" /></span><span class="text_2">test_path=</span><span class="text_6">"data/chap10/Categories_documents/Test/"<br class="calibre4" /></span><span class="text_2">data_train=load_files(</span><span class="text_10">container_path</span><span class="text_2">=train_path</span><span class="text_">,</span><span class="text_10">encoding</span><span class="text_2">=</span><span class="text_6">'utf-16'</span><span class="text_2">)<br class="calibre4" />data_test=load_files(</span><span class="text_10">container_path</span><span class="text_2">=test_path</span><span class="text_">,</span><span class="text_10">encoding</span><span class="text_2">=</span><span class="text_6">'utf-16'</span><span class="text_2">)<br class="calibre4" /><br class="calibre4" /></span><span class="text_7"># Tách dữ liệu và đếm từ sử dụng CountVectorizer<br class="calibre4" /></span><span class="text_2">count_vectorizer=CountVectorizer()<br class="calibre4" />train_tc=count_vectorizer.fit_transform(</span><span class="text_10">raw_documents</span><span class="text_2">=data_train.data)<br class="calibre4" /><br class="calibre4" /></span><span class="text_7"># Tạo TF-IDF và train nó dựa trên dữ liệu train text count<br class="calibre4" /></span><span class="text_2">tfidf=TfidfTransformer(</span><span class="text_10">use_idf</span><span class="text_2">=</span><span class="text_">True</span><span class="text_2">)<br class="calibre4" />train_tfidf=tfidf.fit_transform(train_tc)<br class="calibre4" /><br class="calibre4" /></span><span class="text_7"># Cía này là tạo bộ phân loại sử dụng Pipeline<br class="calibre4" /></span><span class="text_2">text_clf=Pipeline([(</span><span class="text_6">'vect'</span><span class="text_">, </span><span class="text_2">CountVectorizer())</span><span class="text_">, </span><span class="text_2">(</span><span class="text_6">'tfidf'</span><span class="text_">, </span><span class="text_2">TfidfTransformer(</span><span class="text_10">use_idf</span><span class="text_2">=</span><span class="text_">True</span><span class="text_2">))</span><span class="text_">, </span><span class="text_2">(</span><span class="text_6">'clf'</span><span class="text_">, </span><span class="text_2">SGDClassifier(</span><span class="text_10">loss</span><span class="text_2">=</span><span class="text_6">'hinge'</span><span class="text_">, </span><span class="text_10">penalty</span><span class="text_2">=</span><span class="text_6">'l2'</span><span class="text_">, </span><span class="text_10">alpha</span><span class="text_2">=</span><span class="text_9">1e-3</span><span class="text_">, </span><span class="text_10">random_state</span><span class="text_2">=</span><span class="text_9">42</span><span class="text_">, </span><span class="text_10">verbose</span><span class="text_2">=</span><span class="text_9">1</span><span class="text_2">))</span><span class="text_">,</span><span class="text_2">])<br class="calibre4" /></span><span class="text_7"># Tạo một vài dữ liệu để dự đoán<br class="calibre4" /></span><span class="text_2">input_data=[<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">'Không có nhiều bất ngờ với những cầu thủ vừa được HLV Park Hang-seo bổ sung trong đợt tập trung thứ hai cho vòng loại World Cup 2022'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">'Nghệ sĩ saxophone Xuân Hiếu mất ở tuổi 47 vào trưa 30/9 tại nhà riêng sau thời gian điều trị ung thư.'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">'Xuất hiện trojan giả mạo bản vá của McAfee'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">'Cuộc sống độc thân của Hiền Thục ở Mỹ'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">'Để sở hữu một làn da sáng mịn, ngoài chế độ dinh dưỡng giàu vitamin và khoáng chất, bạn cần thường xuyên vệ sinh sạch sẽ và và duy trì độ ẩm cần thiết cho da.'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">'Những siêu hệ thống giao thông Trung Quốc'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">'Giáo viên trường tiểu học và THCS bán trú Sơn Bua vượt 3 km đường rừng vào các bản làng ở khu dân cư Nước Mù vận động học sinh đến lớp.'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">'Yoshiyuki Kiuchi (49 tuổi) thường cố tình đâm sầm để gây thương tích cho người vừa đi bộ vừa sử dụng điện thoại.'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">'Kinh doanh quán cà phê không là cách đầu tư nhanh có lãi, phải có vốn mạnh và thật kiên nhẫn.'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">'Show diễn của Quang Hà sau vụ cháy'<br class="calibre4" /></span><span class="text_2">]<br class="calibre4" /></span><span class="text_7">#Sử dụng thuật toán Multinomial Naive Bayes để training data<br class="calibre4" /></span><span class="text_2">classifier=MultinomialNB().fit(train_tfidf</span><span class="text_">,</span><span class="text_2">data_train.target)<br class="calibre4" /></span><span class="text_7"># Sử dụng pipeline để train data. Chú ý data ở đây là data gốc download không phải là data đã được biến đổi<br class="calibre4" /></span><span class="text_2">text_clf.fit(data_train.data</span><span class="text_">,</span><span class="text_2">data_train.target)<br class="calibre4" /></span><span class="text_7">#Biến đổi dữ liệu input sử dụng vectorizer<br class="calibre4" /></span><span class="text_2">input_tc=count_vectorizer.transform(input_data)<br class="calibre4" /></span><span class="text_7">#print(input_tc)<br class="calibre4" /># Biến đổi dữ liệu sử dụng tfidf để có thể sử dụng với classifer<br class="calibre4" /></span><span class="text_2">input_tfidf=tfidf.transform(input_tc)<br class="calibre4" /><br class="calibre4" /></span><span class="text_7"># Dự đoán kết quả sử dụng pipeline<br class="calibre4" /></span><span class="text_2">predictions=text_clf.predict(input_data)<br class="calibre4" /></span><span class="text_7"># dự đoán kết quả đầu ra sử dụng vector đã được biến đổi dưới dạng tf-idf sử dụng MultinomialNB<br class="calibre4" />#predictions=classifier.predict(input_tfidf)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_2">(predictions)<br class="calibre4" /></span><span class="text_7">#Lấy dữ liệu được dán nhãn từ data đã download<br class="calibre4" /></span><span class="text_2">categories=data_train.target_names<br class="calibre4" /></span><span class="text_7"># in kết quả<br class="calibre4" /></span><span class="text_">for </span><span class="text_2">sent</span><span class="text_">,</span><span class="text_2">category </span><span class="text_">in </span><span class="text_8">zip</span><span class="text_2">(input_data</span><span class="text_">,</span><span class="text_2">predictions):<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"</span><span class="text_">\n</span><span class="text_6">Đoạn văn:"</span><span class="text_">,</span><span class="text_2">sent</span><span class="text_">,</span><span class="text_6">"</span><span class="text_">\n</span><span class="text_6">Dự đoán thể loại:"</span><span class="text_">,</span><span class="text_2">categories[category])</span></p><p class="block_11"></p></div>
	<p class="block_12">&nbsp;</p>
	<p class="block_1">Kết quả:</p>
	<p class="block_6">Đoạn văn: Không có nhiều bất ngờ với những cầu thủ vừa được HLV Park Hang-seo bổ sung trong đợt tập trung thứ hai cho vòng loại World Cup 2022 </p>
	<p class="block_7">Dự đoán thể loại: Bong da</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Đoạn văn: Nghệ sĩ saxophone Xuân Hiếu mất ở tuổi 47 vào trưa 30/9 tại nhà riêng sau thời gian điều trị ung thư. </p>
	<p class="block_7">Dự đoán thể loại: Am nhac</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Đoạn văn: Xuất hiện trojan giả mạo bản vá của McAfee </p>
	<p class="block_7">Dự đoán thể loại: Hackers va Virus</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Đoạn văn: Cuộc sống độc thân của Hiền Thục ở Mỹ </p>
	<p class="block_7">Dự đoán thể loại: Am nhac</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Đoạn văn: Để sở hữu một làn da sáng mịn, ngoài chế độ dinh dưỡng giàu vitamin và khoáng chất, bạn cần thường xuyên vệ sinh sạch sẽ và và duy trì độ ẩm cần thiết cho da. </p>
	<p class="block_7">Dự đoán thể loại: Lam dep</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Đoạn văn: Những siêu hệ thống giao thông Trung Quốc </p>
	<p class="block_7">Dự đoán thể loại: Kinh doanh quoc te</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Đoạn văn: Giáo viên trường tiểu học và THCS bán trú Sơn Bua vượt 3 km đường rừng vào các bản làng ở khu dân cư Nước Mù vận động học sinh đến lớp. </p>
	<p class="block_7">Dự đoán thể loại: Giao duc</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Đoạn văn: Yoshiyuki Kiuchi (49 tuổi) thường cố tình đâm sầm để gây thương tích cho người vừa đi bộ vừa sử dụng điện thoại. </p>
	<p class="block_7">Dự đoán thể loại: San pham tin hoc moi</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Đoạn văn: Kinh doanh quán cà phê không là cách đầu tư nhanh có lãi, phải có vốn mạnh và thật kiên nhẫn. </p>
	<p class="block_7">Dự đoán thể loại: Chung khoan</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Đoạn văn: Show diễn của Quang Hà sau vụ cháy </p>
	<p class="block_8">Dự đoán thể loại: San khau dien anh</p>
	<p class="block_1">Như bạn có thể thấy bộ phân loại làm việc khá hiệu quả. Sẽ hiệu quả hơn nếu bạn sử dụng dữ liệu train tốt hơn. Khi thay đổi 2 bộ phân loại bạn sẽ thấy phân loại sử dụng Pipeline cho kết quả chính xác hơn </p>
	<div class="frame_"><p class="block_10"><span class="text_2"># Dự đoán kết quả sử dụng pipeline<br class="calibre4" /></span><span class="text_1">predictions=text_clf.predict(input_data)<br class="calibre4" /></span><span class="text_2"># dự đoán kết quả đầu ra sử dụng vector đã được biến đổi dưới dạng tf-idf sử dụng MultinomialNB<br class="calibre4" />#predictions=classifier.predict(input_tfidf)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_1">(predictions)</span></p><p class="block_11"></p></div>
	<p class="block_12">&nbsp;</p>
	<p class="block_5">Xây dựng bộ nhận diện giới tính</p>
	<p class="block_1">Bộ nhận diện giới tính là một vấn đề thú vị. Ở đây chúng ta sẽ sử dụng một hàm dánh giá heuristic để xây dựng một vector tính năng (feature vector) và sử dụng nó để dạy (train) một bộ phân loại. Hàm đánh giá heuristic sẽ được sử dụng ở đây là hàm <i class="calibre5">N ký tự cuối</i> cho tên. Ví dụ, nếu tên kết thúc với từ <i class="calibre5">ia </i>, thường là tên của một người phụ nữ vd như Amelia Genelia. Mặt khác nếu tên kết thúc với từ rk nó là tên của đàn ông vd Clark, Mark. Vì thế chúng ta không biết được chính xác số ký tự sẽ sử dụng, chúng ta sẽ thử một vài tham số N và tìm ra câu trả lời tốt nhất.</p>
	<div class="frame_"><p class="block_10"><span class="text_">import </span><span class="text_2">nltk<br class="calibre4" />nltk.data.path.append(</span><span class="text_6">"D:</span><span class="text_">\\</span><span class="text_6">PycharmProjects</span><span class="text_">\\</span><span class="text_6">AILearn</span><span class="text_">\\</span><span class="text_6">NLTK"</span><span class="text_2">)<br class="calibre4" /></span><span class="text_">import </span><span class="text_2">random<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk </span><span class="text_">import </span><span class="text_2">NaiveBayesClassifier<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.classify </span><span class="text_">import </span><span class="text_2">accuracy </span><span class="text_">as </span><span class="text_2">nacc<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.corpus </span><span class="text_">import </span><span class="text_2">names<br class="calibre4" /><br class="calibre4" /></span><span class="text_7"># tạo một hàm để phân tách ký tự cuối N cho từ được nhập vào<br class="calibre4" /></span><span class="text_">def </span><span class="text_11">extract_feature</span><span class="text_2">(word</span><span class="text_">,</span><span class="text_2">N=</span><span class="text_9">2</span><span class="text_2">):<br class="calibre4" /><span class="calibre6">    last_n_letters=word[-N:]</span></span><span class="text_2"><br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">return </span><span class="text_2">{</span><span class="text_6">'feature'</span><span class="text_2">:last_n_letters.lower()}<br class="calibre4" /></span><span class="text_7">#Tạo hàm main và lấy tên và training nó từ scikit-learn. dữ liệu này gồm tên nam và nữ đã được dán nhãn :<br class="calibre4" /></span><span class="text_">if </span><span class="text_2">__name__==</span><span class="text_6">"__main__"</span><span class="text_2">:<br class="calibre4" /><span class="calibre6">    male_list=[(name</span></span><span class="text_">,</span><span class="text_6">'male'</span><span class="text_2">) </span><span class="text_">for </span><span class="text_2">name </span><span class="text_">in </span><span class="text_2">names.words(</span><span class="text_6">'male.txt'</span><span class="text_2">)]<br class="calibre4" /><span class="calibre6">    female_list=[(name</span></span><span class="text_">,</span><span class="text_6">'female'</span><span class="text_2">) </span><span class="text_">for </span><span class="text_2">name </span><span class="text_">in </span><span class="text_2">names.words(</span><span class="text_6">'female.txt'</span><span class="text_2">)]<br class="calibre4" /><br class="calibre4" /><span class="calibre6">    data=(male_list+female_list)</span></span><span class="text_2"><br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Tạo bộ random number để xáo trộn data:<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">random.seed(</span><span class="text_9">5</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">    random.shuffle(data)</span></span><span class="text_2"><br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Tạo một vài tên để sử dụng test:<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">input_names=[</span><span class="text_6">'Alexander'</span><span class="text_">,</span><span class="text_6">'Danielle'</span><span class="text_">,</span><span class="text_6">'David'</span><span class="text_">,</span><span class="text_6">'Cheryl'</span><span class="text_2">]<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Chia dữ liệu để dùng cho train và test:<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">num_train=</span><span class="text_8">int</span><span class="text_2">(</span><span class="text_9">0.8</span><span class="text_2">*</span><span class="text_8">len</span><span class="text_2">(data))<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Chúng ta sẽ sử dụng thuật toán N ký tự cuối như một vector tính năng để dự đoán giới tính. Chúng ta sẽ có một vài tham số để thấy hiệu suất khác nhau. Trường hợp này chúng ta sẽ đi từ 1-&gt;6<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">for </span><span class="text_2">i </span><span class="text_">in </span><span class="text_8">range</span><span class="text_2">(</span><span class="text_9">1</span><span class="text_">,</span><span class="text_9">6</span><span class="text_2">):<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"Số ký tự cuối:"</span><span class="text_">,</span><span class="text_2">i)<br class="calibre4" /><span class="calibre6">        features=[(extract_feature(n</span></span><span class="text_">,</span><span class="text_2">i)</span><span class="text_">,</span><span class="text_2">gender) </span><span class="text_">for </span><span class="text_2">(n</span><span class="text_">,</span><span class="text_2">gender) </span><span class="text_">in </span><span class="text_2">data]<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_7"># phân chia dữ liệu để train và test<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_2">train_data</span><span class="text_">,</span><span class="text_2">test_data= features[:num_train]</span><span class="text_">,</span><span class="text_2">features[num_train:]<br class="calibre4" /><br class="calibre4" /><span class="calibre6">        classifier=NaiveBayesClassifier.train(train_data)</span></span><span class="text_2"><br class="calibre4" /><span class="calibre6">        </span></span><span class="text_7"># Tính toán độ chính xác của bộ phân loại sử dụng hàm có sẵn trong NLTK:<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_2">accuracy=</span><span class="text_8">round</span><span class="text_2">(</span><span class="text_9">100</span><span class="text_2">*nacc(classifier</span><span class="text_">,</span><span class="text_2">test_data)</span><span class="text_">,</span><span class="text_9">2</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"Độ chính xác ="</span><span class="text_">,</span><span class="text_8">str</span><span class="text_2">(accuracy)</span><span class="text_">,</span><span class="text_6">'%'</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_7"># Dự đoán kết quả cho mỗi tên chúng ta đã tạo ra<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_">for </span><span class="text_2">name </span><span class="text_">in </span><span class="text_2">input_names:<br class="calibre4" /><span class="calibre6">            </span></span><span class="text_8">print</span><span class="text_2">(name</span><span class="text_">,</span><span class="text_6">"==&gt;"</span><span class="text_">,</span><span class="text_2">classifier.classify(extract_feature(name</span><span class="text_">,</span><span class="text_2">i)))</span></p><p class="block_11"></p></div>
	<p class="block_12">&nbsp;</p>
	<p class="block_1">Kết quả:</p>
	<p class="block_6">Số ký tự cuối: 1</p>
	<p class="block_7">Độ chính xác = 74.7 %</p>
	<p class="block_7">Alexander ==&gt; male</p>
	<p class="block_7">Danielle ==&gt; female</p>
	<p class="block_7">David ==&gt; male</p>
	<p class="block_7">Cheryl ==&gt; male</p>
	<p class="block_7">Số ký tự cuối: 2</p>
	<p class="block_7">Độ chính xác = 78.79 %</p>
	<p class="block_7">Alexander ==&gt; male</p>
	<p class="block_7">Danielle ==&gt; female</p>
	<p class="block_7">David ==&gt; male</p>
	<p class="block_7">Cheryl ==&gt; female</p>
	<p class="block_7">Số ký tự cuối: 3</p>
	<p class="block_7">Độ chính xác = 77.22 %</p>
	<p class="block_7">Alexander ==&gt; male</p>
	<p class="block_7">Danielle ==&gt; female</p>
	<p class="block_7">David ==&gt; male</p>
	<p class="block_7">Cheryl ==&gt; female</p>
	<p class="block_7">Số ký tự cuối: 4</p>
	<p class="block_7">Độ chính xác = 69.98 %</p>
	<p class="block_7">Alexander ==&gt; male</p>
	<p class="block_7">Danielle ==&gt; female</p>
	<p class="block_7">David ==&gt; male</p>
	<p class="block_7">Cheryl ==&gt; female</p>
	<p class="block_7">Số ký tự cuối: 5</p>
	<p class="block_7">Độ chính xác = 64.63 %</p>
	<p class="block_7">Alexander ==&gt; male</p>
	<p class="block_7">Danielle ==&gt; female</p>
	<p class="block_7">David ==&gt; male</p>
	<p class="block_8">Cheryl ==&gt; female</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_1">Đây là kết quả khi phân loại dữ liệu tên bằng tiếng anh. Mình sẽ xây dựng bộ phân loại tên tiếng việt sau. đm</p>
	<p class="block_5">Xây dựng một bộ phân tích cảm xúc: sentiment analyzer</p>
	<p class="block_1">Phân tích cảm xúc là quá trình xác định cảm xúc của một đoạn văn bản nhất định. VD, bạn sử dụng nó để xác định xem một đoạn đánh giá phim là tích cực hay tiêu cực ( chán hoặc hay). Đây là một trong những ứng dụng thông dụng nhất của việc xử lý ngôn ngữ. Chúng ta có thể thêm nhiều thể loại dựa trên những vấn đề có trong tay. Kỹ thuật này thường được sử dụng để hiểu <span class="calibre1">được cảm giác của mọi người cảm thấy thế nào về sản phẩm, thương hiệu hoặc một chủ đề. Nó thường được sử dụng để phân tích chiến dịch quảng cáo,  các cuộc thăm dò ý kiến, sự kiện truyền thông, đánh giá sản phẩm trên các website thương mại…...Giờ chúng ta hãy xem cách xác định cảm xúc của một đánh giá phim.</span></p>
	<p class="block_1">Chúng ta sẽ sử dụng bộ phân loại Naïve Bayes .Trước tiên chúng ta cần tách tất cả những từ đặc biệt trong đoạn văn bản. Bộ phân loại NLTK cần dữ liệu này để xắp xếp theo mẫu và có thể sử dụng nó. Khi chúng ta chia dữ liệu văn bản vào trong bộ dữ liệu train, và bộ dữ liệu test, chúng ta sẽ train một bộ phân loại Naïve Bayes để phân loại những đánh giá thành đánh giá tích cực và đánh giá tiêu cực. Những thông tin này rất thú vị bởi vì nó sẽ nói cho chúng ta biết những từ nào sẽ được sử dụng để biểu hiện các phản ứng cảm xúc khác nhau.</p>
	<div class="frame_"><p class="block_10"><span class="text_">import </span><span class="text_2">nltk<br class="calibre4" />nltk.data.path.append(</span><span class="text_6">"D:</span><span class="text_">\\</span><span class="text_6">PycharmProjects</span><span class="text_">\\</span><span class="text_6">AILearn</span><span class="text_">\\</span><span class="text_6">NLTK"</span><span class="text_2">)<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.corpus </span><span class="text_">import </span><span class="text_2">movie_reviews<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.classify </span><span class="text_">import </span><span class="text_2">NaiveBayesClassifier<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.classify.util </span><span class="text_">import </span><span class="text_2">accuracy </span><span class="text_">as </span><span class="text_2">nacc<br class="calibre4" /><br class="calibre4" /></span><span class="text_7"># Tạo hàm để xay dựng một dictionary dựa trên những từ được nhập vào và trả lại giá trị:<br class="calibre4" /></span><span class="text_">def </span><span class="text_11">extract_features</span><span class="text_2">(words):<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">return </span><span class="text_8">dict</span><span class="text_2">((word</span><span class="text_">,True</span><span class="text_2">) </span><span class="text_">for </span><span class="text_2">word </span><span class="text_">in </span><span class="text_2">words)<br class="calibre4" /></span><span class="text_7">#Tạo hàm main và load dữ liệu những đánh giá phim đã được gắn nhãn:<br class="calibre4" /></span><span class="text_">if </span><span class="text_2">__name__==</span><span class="text_6">"__main__"</span><span class="text_2">:<br class="calibre4" /><span class="calibre6">    fileids_pos=movie_reviews.fileids(</span></span><span class="text_6">'pos'</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">    fileids_neg=movie_reviews.fileids(</span></span><span class="text_6">'neg'</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Tách những features từ những ddanhs giá và dán nhãn nó<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">features_pos=[(extract_features(movie_reviews.words(</span><span class="text_10">fileids</span><span class="text_2">=[f]))</span><span class="text_">,</span><span class="text_6">'Có vẻ thích'</span><span class="text_2">) </span><span class="text_">for </span><span class="text_2">f </span><span class="text_">in </span><span class="text_2">fileids_pos]<br class="calibre4" /><span class="calibre6">    features_neg = [(extract_features(movie_reviews.words(</span></span><span class="text_10">fileids</span><span class="text_2">=[f]))</span><span class="text_">, </span><span class="text_6">'Hình như méo thích'</span><span class="text_2">) </span><span class="text_">for </span><span class="text_2">f </span><span class="text_">in </span><span class="text_2">fileids_neg]<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7">#Tạo tỉ lệ chia<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">threshold=</span><span class="text_9">0.8<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">num_pos=</span><span class="text_8">int</span><span class="text_2">(threshold*</span><span class="text_8">len</span><span class="text_2">(features_pos))<br class="calibre4" /><span class="calibre6">    num_neg=</span></span><span class="text_8">int</span><span class="text_2">(threshold*</span><span class="text_8">len</span><span class="text_2">(features_neg))<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Tách các vector đặc trưng để train và test<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">features_train=features_pos[:num_pos]+features_neg[:num_neg]<br class="calibre4" /><span class="calibre6">    features_test=features_pos[num_pos:]+features_neg[num_neg:]</span></span><span class="text_2"><br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Sử dụng Naive Bayes để tạo bộ phân loại và tính độ chính xác<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">classifier=NaiveBayesClassifier.train(features_train)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"Độ chính xác của bộ phân loại: "</span><span class="text_">,</span><span class="text_8">round</span><span class="text_2">(nacc(classifier</span><span class="text_">,</span><span class="text_2">features_test)*</span><span class="text_9">100</span><span class="text_">,</span><span class="text_9">2</span><span class="text_2">)</span><span class="text_">,</span><span class="text_6">"%"</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">    N=</span></span><span class="text_9">15<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># In top 15 những từ có giá trị thông tin nhất<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_6">"""for i,item in enumerate(classifier.most_informative_features()):<br class="calibre4" /><span class="calibre6">        print(str(i+1)+'.'+item[0])</span></span><span class="text_6"><br class="calibre4" /><span class="calibre6">        if i==N-1:</span></span><span class="text_6"><br class="calibre4" /><span class="calibre6">            break"""</span></span><span class="text_6"><br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Tạo một vài review ví dụ sử dụng để test<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">input_reviews = [</span><span class="text_6">'The costumes in this movie were great'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">                     </span></span><span class="text_6">'I think the story was terrible and the characters were very weak'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">                     </span></span><span class="text_6">'People say that the director of the movie is amazing'</span><span class="text_">,<br class="calibre4" /><span class="calibre6">                     </span></span><span class="text_6">'This is such an idiotic movie. I will not recommend it to anyone.'</span><span class="text_2">]<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Tạo vòng lặp để dự đoán từng kết quả<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">for </span><span class="text_2">review </span><span class="text_">in </span><span class="text_2">input_reviews:<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"Đánh giá: "</span><span class="text_">,</span><span class="text_2">review)<br class="calibre4" /><span class="calibre6">        probabilities=classifier.prob_classify(extract_features(review))</span></span><span class="text_2"><br class="calibre4" /><span class="calibre6">        predict_sentiment=probabilities.max()</span></span><span class="text_2"><br class="calibre4" /><span class="calibre6">        </span></span><span class="text_7"># in kết quả<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"Dự đoán cảm xúc:"</span><span class="text_">,</span><span class="text_2">predict_sentiment)<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_7"># Dự đoán tỉ lệ chính xác<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">"Độ chính xác"</span><span class="text_">,</span><span class="text_8">round</span><span class="text_2">(probabilities.prob(predict_sentiment)</span><span class="text_">,</span><span class="text_9">2</span><span class="text_2">))</span></p><p class="block_11"></p></div>
	<p class="block_12">&nbsp;</p>
	<p class="block_1">Kết quả:</p>
	<p class="block_6"><span class="calibre6">Độ chính xác của bộ phân loại:  73.5 %</span></p>
	<p class="block_7"><span class="calibre6">Đánh giá:  The costumes in this movie were great</span></p>
	<p class="block_7">Dự đoán cảm xúc: Có vẻ thích</p>
	<p class="block_7">Độ chính xác 0.65</p>
	<p class="block_7"><span class="calibre6">Đánh giá:  I think the story was terrible and the characters were very weak</span></p>
	<p class="block_7">Dự đoán cảm xúc: Hình như méo thích</p>
	<p class="block_7">Độ chính xác 0.74</p>
	<p class="block_7"><span class="calibre6">Đánh giá:  People say that the director of the movie is amazing</span></p>
	<p class="block_7">Dự đoán cảm xúc: Có vẻ thích</p>
	<p class="block_7">Độ chính xác 0.6</p>
	<p class="block_7"><span class="calibre6">Đánh giá:  This is such an idiotic movie. I will not recommend it to anyone.</span></p>
	<p class="block_7">Dự đoán cảm xúc: Có vẻ thích</p>
	<p class="block_8">Độ chính xác 0.57</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_5">Mô hình chủ đề sử dụng Latent Dirichlet Allocation (Phân bổ LD)</p>
	<p class="block_1"><b class="calibre2">Mô hình chủ đề (Topic Modeling)</b> là quá trình xử lý nhận dạng thành phần trong dữ liệu văn bản trao đổi giữa các chủ đề. Nếu văn bản chứa nhiều chủ đề thì kỹ thuật này có thể sử dụng để nhận dạng và phân chia chúng. Chúng ta làm điều này để khám phá cấu trúc các chủ đề ẩn chứa trong một bộ văn bản.</p>
	<p class="block_1">Mô hình chủ đề giúp chúng ta tổ chức lại tài liệu văn bản một cách tối ưu, và sau đó được sử dụng để phân tích. Một thứ cần chú ý ở đây là thuật toán mô hình chủ đề không cần dữ liệu đã được dán nhãn trước. Nó giống như học không giám sát (unsupervised learning) Nó sẽ tự nhận dạng thành phần trên nó. Với khối lượng dữ liệu văn bản khổng lồ được tạo ra trên internet, mô hình này trở nên quan trọng bởi vì nó giúp chúng ta tóm tắt lại tất cả các dữ liệu, mà nếu không có nó thì mọi thứ trở thành không thể.</p>
	<p class="block_1"><b class="calibre2">Phân bổ Latent Dirichlet (Latern Dirichlet Allocation)</b> Là một thuật giải mô hình chủ đề. Trong đó khái niệm cơ bản được đưa ra là một đoạn văn bản nhất định là sự kết hợp của nhiều chủ đề. Hãy thử xem một câu như sau: Biểu diễn biểu đồ dữ liệu là một ứng dụng trong phân tích kinh tế. Câu này có nhiều chủ đề như: dữ liệu, kinh tế, phân tích, biểu diễn biểu đồ. Các chủ đề chi tiết này giúp chúng ta nhận dạng được câu này là một tài liệu lớn. Về bản chất, nó là một mô hình phân tích cố găn để nắm bắt các ý tưởng và tạo một mô hình dựa trên nó. Mô hình giả định tài liệu được tạo ra từ một quá trình xử lý ngẫu nhiên dựa trên những chủ đề. Một chủ đề nghĩa là một sự phân phối các từ vựng cố định. Giờ thì xem modeling topic trong python </p>
	<p class="block_1">Chúng ta sửu dụng thư viện <b class="calibre2">genism</b> trong phần này. Về cách cài đặt thư viện thì nếu đọc từ đầu chắc các bạn không còn thắc mắc nữa. còn chưa biết thì đọc lại phần cũ (8 hay 9 gì đó).</p>
	<div class="frame_"><p class="block_10"><span class="text_">import </span><span class="text_2">nltk<br class="calibre4" />nltk.data.path.append(</span><span class="text_6">"D:</span><span class="text_">\\</span><span class="text_6">PycharmProjects</span><span class="text_">\\</span><span class="text_6">AILearn</span><span class="text_">\\</span><span class="text_6">NLTK"</span><span class="text_2">)<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.tokenize </span><span class="text_">import </span><span class="text_2">RegexpTokenizer<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.corpus </span><span class="text_"><span class="calibre6">import  </span></span><span class="text_2">stopwords<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">nltk.stem.snowball </span><span class="text_">import </span><span class="text_2">SnowballStemmer<br class="calibre4" /></span><span class="text_">from </span><span class="text_2">gensim </span><span class="text_">import </span><span class="text_2">models</span><span class="text_">,</span><span class="text_2">corpora<br class="calibre4" /><br class="calibre4" /></span><span class="text_7"># Tạo một hàm để load dữ liệu. dữ liệu đầu vào gồm có 10 dòng. mỗi dòng là một câu.<br class="calibre4" /></span><span class="text_">def </span><span class="text_11">load_data</span><span class="text_2">(input_file):<br class="calibre4" /><span class="calibre6">    input_file = </span></span><span class="text_8">open</span><span class="text_2">(input_file</span><span class="text_">, </span><span class="text_6">'r'</span><span class="text_">, </span><span class="text_10">encoding</span><span class="text_2">=</span><span class="text_6">'utf-8'</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Loại bỏ các dòng<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">input_string = input_file.read().splitlines()<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Join array lại thành string<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">input_string = </span><span class="text_6">" "</span><span class="text_2">.join(input_string)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">import </span><span class="text_2">re<br class="calibre4" /><span class="calibre6">    input_string = re.split(</span></span><span class="text_6">r"\."</span><span class="text_">, </span><span class="text_2">input_string)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7">#input_string = "\n".join(input_string)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">return </span><span class="text_2">input_string<br class="calibre4" /></span><span class="text_7"># Tạo một hàm để sử lý dữ liệu đầu vào. Bước đầu tiên là phân tách câu (tokenizer)<br class="calibre4" /></span><span class="text_">def </span><span class="text_11">progcess</span><span class="text_2">(input_text):<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7">#Regex torkenizer<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">tokenizer=RegexpTokenizer(</span><span class="text_6">r'\w+'</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Sau đó chúng ta cần biến nó về dạng từ cơ bản (stem word)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">stemmer = SnowballStemmer(</span><span class="text_6">'english'</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Chúng ta cần loại bỏ những từ "dừng" (stopwords) vì nó không cần thiết<br class="calibre4" /><span class="calibre6">    # File stopword-vietnamese lấy ở đây https://github.com/stopwords/vietnamese-stopwords</span></span><span class="text_7"><br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">with </span><span class="text_8">open</span><span class="text_2">(</span><span class="text_6">'data/chap10/vietnamese-stopwords.txt'</span><span class="text_">,</span><span class="text_6">'r'</span><span class="text_">,</span><span class="text_10">encoding</span><span class="text_2">=</span><span class="text_6">'utf-8'</span><span class="text_2">) </span><span class="text_">as </span><span class="text_2">f:<br class="calibre4" /><span class="calibre6">        stop_word=f.read().splitlines()</span></span><span class="text_2"><br class="calibre4" /><span class="calibre6">    stop_words=</span></span><span class="text_8">set</span><span class="text_2">(stop_word)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7">#print(stop_word)<br class="calibre4" /><span class="calibre6">    # Tokenizer input</span></span><span class="text_7"><br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">tokens=tokenizer.tokenize(input_text.lower())<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7">#print(tokens)<br class="calibre4" /><span class="calibre6">    #loại bỏ stopword</span></span><span class="text_7"><br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">tokens=[x </span><span class="text_">for </span><span class="text_2">x </span><span class="text_">in </span><span class="text_2">tokens </span><span class="text_">if not </span><span class="text_2">x </span><span class="text_">in </span><span class="text_2">stop_words]<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7">#print(tokens)<br class="calibre4" /><span class="calibre6">    # stem token</span></span><span class="text_7"><br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">tokens_stemmed=[stemmer.stem(x) </span><span class="text_">for </span><span class="text_2">x </span><span class="text_">in </span><span class="text_2">tokens]<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">return </span><span class="text_2">tokens_stemmed<br class="calibre4" /></span><span class="text_7"># Tạo hàm main để load dữ liệu<br class="calibre4" /></span><span class="text_">if </span><span class="text_2">__name__==</span><span class="text_6">"__main__"</span><span class="text_2">:<br class="calibre4" /><span class="calibre6">    data=load_data(</span></span><span class="text_6">"data/chap10/doaremon.txt"</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">    tokens=[progcess(x) </span></span><span class="text_">for </span><span class="text_2">x </span><span class="text_">in </span><span class="text_2">data]<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7"># Tạo một dict dựa trên những câu đã tokenizer<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">dict_tokens=corpora.Dictionary(tokens)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_7">#Tạo một term matrix sử dụng dict token:<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">doc_term_mat=[dict_tokens.doc2bow(token) </span><span class="text_">for </span><span class="text_2">token </span><span class="text_">in </span><span class="text_2">tokens]<br class="calibre4" /><span class="calibre6">    num_topics=</span></span><span class="text_9">5<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_2">ldamodel = models.ldamodel.LdaModel(doc_term_mat</span><span class="text_">,</span><span class="text_10">num_topics</span><span class="text_2">=num_topics</span><span class="text_">, </span><span class="text_10">id2word</span><span class="text_2">=dict_tokens</span><span class="text_">, </span><span class="text_10">passes</span><span class="text_2">=</span><span class="text_9">25</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">    num_words = </span></span><span class="text_9">10<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">'</span><span class="text_">\n</span><span class="text_6">Top ' </span><span class="text_2">+ </span><span class="text_8">str</span><span class="text_2">(num_words) + </span><span class="text_6">' contributing words to each topic:'</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">    </span></span><span class="text_">for </span><span class="text_2">item </span><span class="text_">in </span><span class="text_2">ldamodel.print_topics(</span><span class="text_10">num_topics</span><span class="text_2">=num_topics</span><span class="text_">,<br class="calibre4" /><span class="calibre6">                                      </span></span><span class="text_10">num_words</span><span class="text_2">=num_words):<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_8">print</span><span class="text_2">(</span><span class="text_6">'</span><span class="text_">\n</span><span class="text_6">Topic'</span><span class="text_">, </span><span class="text_2">item[</span><span class="text_9">0</span><span class="text_2">])<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_7">#<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_2">list_of_strings = item[</span><span class="text_9">1</span><span class="text_2">].split(</span><span class="text_6">' + '</span><span class="text_2">)<br class="calibre4" /><span class="calibre6">        </span></span><span class="text_">for </span><span class="text_2">text </span><span class="text_">in </span><span class="text_2">list_of_strings:<br class="calibre4" /><span class="calibre6">            weight = text.split(</span></span><span class="text_6">'*'</span><span class="text_2">)[</span><span class="text_9">0</span><span class="text_2">]<br class="calibre4" /><span class="calibre6">            word = text.split(</span></span><span class="text_6">'*'</span><span class="text_2">)[</span><span class="text_9">1</span><span class="text_2">]<br class="calibre4" /><span class="calibre6">            </span></span><span class="text_8">print</span><span class="text_2">(word</span><span class="text_">, </span><span class="text_6">'==&gt;'</span><span class="text_">, </span><span class="text_8">str</span><span class="text_2">(</span><span class="text_8">round</span><span class="text_2">(</span><span class="text_8">float</span><span class="text_2">(weight) * </span><span class="text_9">100</span><span class="text_">, </span><span class="text_9">2</span><span class="text_2">)) + </span><span class="text_6">'%'</span><span class="text_2">)</span></p><p class="block_11"></p></div>
	<p class="block_12">&nbsp;</p>
	<p class="block_1">Kết quả:</p>
	<p class="block_6">Top 10 contributing words to each topic:</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Topic 0</p>
	<p class="block_7">"phố" ==&gt; 2.7%</p>
	<p class="block_7">"xeko" ==&gt; 2.5%</p>
	<p class="block_7">"kiểu" ==&gt; 2.2%</p>
	<p class="block_7">"cổ" ==&gt; 2.1%</p>
	<p class="block_7">"tập" ==&gt; 1.7%</p>
	<p class="block_7">"giàu" ==&gt; 1.6%</p>
	<p class="block_7">"chaien" ==&gt; 1.4%</p>
	<p class="block_7">"tokyo" ==&gt; 1.4%</p>
	<p class="block_7">"gốc" ==&gt; 1.4%</p>
	<p class="block_7">"dekhi" ==&gt; 1.4%</p>
	<p class="block_13">&nbsp;</p>
	<p class="block_7">Topic 1</p>
	<p class="block_7">"dekhi" ==&gt; 2.3%</p>
	<p class="block_7">"xuka" ==&gt; 1.9%</p>
	<p class="block_7">"tầng" ==&gt; 1.6%</p>
	<p class="block_7">"lớp" ==&gt; 1.6%</p>
	<p class="block_7">"học" ==&gt; 1.2%</p>
	<p class="block_7">"cổ" ==&gt; 1.2%</p>
	<p class="block_7">"bé" ==&gt; 1.2%</p>
	<p class="block_7">"đất" ==&gt; 1.2%</p>
	<p class="block_7">"tiền" ==&gt; 1.2%</p>
	<p class="block_7">"phố" ==&gt; 1.2%</p>
	<p class="block_8">…… còn mấy topic nữa :D</p>
	<p class="block_1">Đọc thì có thể hiểu độ liên quan của từ đối với chủ đề nói đến: vd topic 0 : xeko,chaien,dekhi đều giàu nhà phố cổ :D topic1: xuka dekhi tầng lớp có học nhà phố.</p>
	<p class="block_5">Tổng kết.</p>
	<p class="block_1">Trong chương này chúng ta học về các khái niệm cơ bản trong sử lý ngôn ngữ tự nhiên (Natural Language Process &ndash;NLP) bằng thư viện nltk trong Python.</p>
	<p class="block_1">Chúng ta thảo luận về cách xử lý ngôn ngữ văn bản: </p>
	<p class="block_16">1: tokenization: phân tách câu thành nhiều phần. </p>
	<p class="block_16">2: stemmer: Biến câu trở vê dạng cơ bản sử dụng steamer và lemmatization</p>
	<p class="block_16">3: stopwords: Loại bỏ những từ không cần thiết.</p>
	<p class="block_16"><span class="calibre1">3: chunker  : Khái quát chủ đề</span></p>
	<p class="block_1">Chúng ta đã xây dựng một bộ phân loại chủ đề, xắp xếp dữ liệu blab la bla ….</p>
	<p class="block_1">Trong chương tiếp theo chúng ta sẽ học về cách mô hình dữ liệu tuần tự (modeling sequential data) sử dụng mô hình Hidden Markov.</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>
	<p class="block_12">&nbsp;</p>

</div>

</body></html>

<footer class=" footline" >
	
</footer>


        
        </div> 
        

      </div>

    <div id="navigation">
        
        
        
        
            
            
                
                    
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
        
        


	 
	 
		
			<a class="nav nav-prev" href="/ai-with-python/chapter9/" title="C9: Xây dựng game cùng với AI"> <i class="fa fa-chevron-left"></i></a>
		
		
			<a class="nav nav-next" href="/ai-with-python/chapter11/" title="C11: Sequential Data" style="margin-right: 0px;"><i class="fa fa-chevron-right"></i></a>
		
	
    </div>

    </section>
    
    <div style="left: -1000px; overflow: scroll; position: absolute; top: -1000px; border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;">
      <div style="border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;"></div>
    </div>
    <script src="/js/clipboard.min.js?1572419511"></script>
    <script src="/js/perfect-scrollbar.min.js?1572419511"></script>
    <script src="/js/perfect-scrollbar.jquery.min.js?1572419511"></script>
    <script src="/js/jquery.sticky.js?1572419511"></script>
    <script src="/js/featherlight.min.js?1572419511"></script>
    <script src="/js/highlight.pack.js?1572419511"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="/js/modernizr.custom-3.6.0.js?1572419511"></script>
    <script src="/js/learn.js?1572419511"></script>
    <script src="/js/hugo-learn.js?1572419511"></script>

    <link href="/mermaid/mermaid.css?1572419511" rel="stylesheet" />
    <script src="/mermaid/mermaid.js?1572419511"></script>
    <script>
        mermaid.initialize({ startOnLoad: true });
    </script>
    

  </body>
</html>

