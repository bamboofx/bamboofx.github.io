<!DOCTYPE html>
<html lang="en" class="js csstransforms3d">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="generator" content="Hugo 0.57.2" />
    <meta name="description" content="">


    <link rel="icon" href="/images/favicon.png" type="image/png">

    <title>C3: Ensemble Learing :: Bamboofx&#39;s or NTVFX&#39;s Site</title>

    
    <link href="/css/nucleus.css?1572419511" rel="stylesheet">
    <link href="/css/fontawesome-all.min.css?1572419511" rel="stylesheet">
    <link href="/css/hybrid.css?1572419511" rel="stylesheet">
    <link href="/css/featherlight.min.css?1572419511" rel="stylesheet">
    <link href="/css/perfect-scrollbar.min.css?1572419511" rel="stylesheet">
    <link href="/css/auto-complete.css?1572419511" rel="stylesheet">
    <link href="/css/atom-one-dark-reasonable.css?1572419511" rel="stylesheet">
    <link href="/css/theme.css?1572419511" rel="stylesheet">
    <link href="/css/hugo-theme.css?1572419511" rel="stylesheet">
    
      <link href="/css/theme-blue.css?1572419511" rel="stylesheet">
    

    <script src="/js/jquery-3.3.1.min.js?1572419511"></script>

    <style>
      :root #header + #content > #left > #rlblock_left{
          display:none !important;
      }
      
    </style>
    
  </head>
  <body class="" data-url="/ai-with-python/chapter3/">
    <nav id="sidebar" class="">



  <div id="header-wrapper">
    <div id="header">
      <a id="logo" href="https://bamboofx.github.io/">
  <img src="https://bamboofx.github.io/images/logo.png "> </img>
</a>

    </div>
    
        <div class="searchbox">
    <label for="search-by"><i class="fas fa-search"></i></label>
    <input data-search-input id="search-by" type="search" placeholder="Search...">
    <span data-search-clear=""><i class="fas fa-times"></i></span>
</div>

<script type="text/javascript" src="/js/lunr.min.js?1572419511"></script>
<script type="text/javascript" src="/js/auto-complete.js?1572419511"></script>
<script type="text/javascript">
    
        var baseurl = "https:\/\/bamboofx.github.io\/";
    
</script>
<script type="text/javascript" src="/js/search.js?1572419511"></script>

    
  </div>

    <div class="highlightable">
    <ul class="topics">

        
          
          


 
  
    
    <li data-nav-id="/ai-with-python/" title="AI with Python (Prateek Joshi)" class="dd-item 
        parent
        
        
        ">
      <a href="/ai-with-python/">
          AI with Python (Prateek Joshi)
          
      </a>
      
      
        <ul>
          
          
          
          
        
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter1/" title="C1: Trí thông minh nhân tạo là gì?" class="dd-item ">
        <a href="/ai-with-python/chapter1/">
        C1: Trí thông minh nhân tạo là gì?
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter2/" title="C2: Classification and Regression" class="dd-item ">
        <a href="/ai-with-python/chapter2/">
        C2: Classification and Regression
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter3/" title="C3: Ensemble Learing" class="dd-item active">
        <a href="/ai-with-python/chapter3/">
        C3: Ensemble Learing
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter4/" title="C4: Detecting Patterns with Unsupervised Learning" class="dd-item ">
        <a href="/ai-with-python/chapter4/">
        C4: Detecting Patterns with Unsupervised Learning
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter5/" title="C5: Building Recommender Systems" class="dd-item ">
        <a href="/ai-with-python/chapter5/">
        C5: Building Recommender Systems
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter6/" title="C6: Logic Programing" class="dd-item ">
        <a href="/ai-with-python/chapter6/">
        C6: Logic Programing
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter7/" title="C7: Tìm kiếm Heuristic" class="dd-item ">
        <a href="/ai-with-python/chapter7/">
        C7: Tìm kiếm Heuristic
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter8/" title="C8: Thuật toán di truyền - Genetic Alogrithms" class="dd-item ">
        <a href="/ai-with-python/chapter8/">
        C8: Thuật toán di truyền - Genetic Alogrithms
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter9/" title="C9: Xây dựng game cùng với AI" class="dd-item ">
        <a href="/ai-with-python/chapter9/">
        C9: Xây dựng game cùng với AI
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter10/" title="C10: Natural Language Processing" class="dd-item ">
        <a href="/ai-with-python/chapter10/">
        C10: Natural Language Processing
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter11/" title="C11: Sequential Data" class="dd-item ">
        <a href="/ai-with-python/chapter11/">
        C11: Sequential Data
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter12/" title="C12: Speech Recognizer" class="dd-item ">
        <a href="/ai-with-python/chapter12/">
        C12: Speech Recognizer
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/chapter13/" title="C13: Object Detection and Tracking" class="dd-item ">
        <a href="/ai-with-python/chapter13/">
        C13: Object Detection and Tracking
        
        </a>
    </li>
     
  
 

            
          
            
            


 
  
    
      <li data-nav-id="/ai-with-python/disqus/" title="" class="dd-item ">
        <a href="/ai-with-python/disqus/">
        
        
        </a>
    </li>
     
  
 

            
          
        
        </ul>
              
    </li>
  
 

          
          


 
  
    
    <li data-nav-id="/numpy/" title="NumPy cơ bản" class="dd-item 
        
        
        
        ">
      <a href="/numpy/">
          NumPy cơ bản
          
      </a>
      
              
    </li>
  
 

          
          


 
  
    
    <li data-nav-id="/about/" title="about" class="dd-item 
        
        
        
        ">
      <a href="/about/">
          About
          
      </a>
      
              
    </li>
  
 

          
         
    </ul>

    
    

    
    <section id="footer">
      <p>Built with <a href="https://github.com/matcornic/hugo-theme-learn"><i class="fas fa-heart"></i></a> from <a href="https://getgrav.org">Grav</a> and <a href="https://gohugo.io/">Hugo</a></p>

    </section>
  </div>
</nav>





        <section id="body">
        <div id="overlay"></div>
        <div class="padding highlightable">
              
              <div>
                <div id="top-bar">
                
                
                <div id="breadcrumbs" itemscope="" itemtype="http://data-vocabulary.org/Breadcrumb">
                    <span id="sidebar-toggle-span">
                        <a href="#" id="sidebar-toggle" data-sidebar-toggle="">
                          <i class="fas fa-bars"></i>
                        </a>
                    </span>
                  
                  <span id="toc-menu"><i class="fas fa-list-alt"></i></span>
                  
                  <span class="links">
                 
                 
                    
          
          
            
            
          
          
            
            
          
          
            <a href='/'>Site</a> > <a href='/ai-with-python/'>AI with Python (Prateek Joshi)</a> > C3: Ensemble Learing
          
         
          
         
          
        
                 
                  </span>
                </div>
                
                    <div class="progress">
    <div class="wrapper">

    </div>
</div>

                
              </div>
            </div>
            
        <div id="head-tags">
        
        </div>
        
        <div id="body-inner">
          
            <h1>
              
              C3: Ensemble Learing
            </h1>
          

        



<html><head><meta http-equiv="Content-Type" content="text/html;charset=utf-8" /><link href="style.css" rel="stylesheet" type="text/css" /><title>PythonAI Chapter3</title></head><body><div class="calibre" id="calibre_link-0">
	<p class="block_">3</p>
	<p lang="vi" class="block_">Phân tích dự đoán cùng với Ensemble Learing</p>
	<p class="block_1">Trong chương này chúng ta học về Ensemble Learning and cách sử dụng nó để làm phân tích dự đoán. Kết thúc chương này chúng ta sẽ hiểu các vấn đều sau:</p>
	<ul class="list_">
	<li class="block_2">Xây dựng nguyên mẫu (models) cùng với Ensemble Learning</li>
	<li class="block_3">Mô hình cây quyết định ( Decision Trees) và làm thế nào để xây dựng một Hàm phân loại Cây quyết định ( Decision Tree Classifier)</li>
	<li class="block_3">Cái gì là Random Forests và Extremely Random Forests, và cách làm thế nào để xây dựng một bộ phân loại dựa trên nó</li>
	<li class="block_3">Ước tính độ tin cậy của các dự đoán</li>
	<li class="block_3">Xử lý sự mất cân bằng của các lớp</li>
	<li class="block_3">Tìm tham số tối ưu cho training bằng cách xử dụng tìm kiếm lưới</li>
	<li class="block_3">Tính toán tính năng quan trọng tương đối</li>
	<li class="block_4">Dự đoán tình hình giao thông dựa trên Extremely Random Forests regressor</li>
</ul>
	<p class="block_5">Ensemble Learing là gì ?</p>
	<p class="block_1"><b class="calibre1">Ensemble Learning </b>là cách xây dựng nhiều mô hình (model) và sau đó kết hợp chúng lại thành một và tạo ra một kết quả tốt hơn những mô hình đó một mình. Như chúng ta đã biết các mô hình (models) đó được tạo ra từ phân loại ( classifer<span class="calibre2">), hồi quy (regressor) hoặc bất cứ cách nào tạo ra  models của riêng nó đều có khả năng tính toán khác nhau và để thực hiện một công việc nhất định, khi kết hợp các mô hình này lại với nhau một cách hợp lý thì sẽ tạo ra một mô hình mới mạnh và có hiệu suất cao hơn khi chỉ sử dụng mô hình một cách riêng lẻ. </span><b class="calibre1">Học tập đồng bộ (Ensemble Learning) </b> được sử dụng trên nhiều lĩnh vực khác nhau bao gồm phân loại dữ liệu (data classification), dự đoán mô hình (predictive modeling), kiểm thử bất thường ( anomaly detection) và nhiều thứ khác nữa.</p>
	<p class="block_1">Tại sao chúng ta cần học tập đồng bộ đầu tiên? Để hiều điều này, chúng ta cần lấy một ví dụ thực tế. Bạn muốn mua một cái TV mới, Nhưng bạn không biết mẫu mới nhất là gì. Nhiệm vụ của bạn là phải tìm kiếm một cái tốt nhất trong tầm giá bạn có thể, nhưng bạn không có đủ hiểu biết trong vấn đề này để đưa ra một quyết định tốt nhất. Khi bạn phải đưa ra một quyết định kiểu dạng thế này bạn phải đi tìm những chuyên gia để tham khảo ý kiến cho vấn đề đó ( tìm kiếm review trên youtube, google ….) Nó sẽ giúp bạn đưa ra một quyết định đúng đắn nhất. Có còn hơn không, thay vì bạn đưa ra quyết định riêng thì bạn thường có xu hướng thu thập thông tin dựa trên quyết định cá nhân và kết hợp vào đó là những ý kiến của những người có chuyên môn. Bởi vì chúng ta thường muốn tối ưu quyết định và giảm thiểu những sai xót.</p>
	<p class="block_5">Xây dựng một mô hình học cùng với học tập đồng bộ (Ensemble Learning)</p>
	<p class="block_1">Khi chúng ta chọn một mô hình, chúng ta thường sử dụng phương pháp là chọn một cái có it lỗi nhất trên dữ liệu training. Vấn đề với phương pháp này là nó có thể không luôn hoạt động tốt. Mô hình này có thể bị thiên vị hoặc không trung với dữ liệu training. THường khi chúng ta tính toán mô hình xử dụng xác nhận chéo. Nó có thể không thể hiện gì cả ở những dữ liệu nó không biết.</p>
	<p class="block_1">Một trong những lý do chính để sử dụng học tập đồng bộ là nó rất hiểu quả bởi nó giảm thiểu nguy cơ lựa trọn trên những mô hình kém. Điều này cho phép nó train dữ liệu một cách đa dạng và sau đó thực hiện tốt trên những dữ liệu chưa biết ( unknow data). Khi chúng ta xây dựng một mô hình sử dụng ensemble learning, những mô hình riêng cần phải đa dạng. Điều này cho phép chúng ( chúng ở đây là cái méo gì thì méo biết- là ensemble learning hay individual models) chọn ra nhiều sắc thái khác nhau trong dữ liệu của chúng ta, vì thế mô hình được tổng hợp sẽ trở nên chính xác hơn.</p>
	<p class="block_1">Sự đa dạng đạt được bằng cách sủ dụng nhiều tham số đào tạo khác nhau cho mỗi mô hình riêng. Nó cho phép những mô hình riêng tạo ra những phán quyết riêng cho dữ liệu đào tạo. Có nghĩa là mỗi mô hình sẽ sử dụng những luật riêng để suy luận, đây là cách mạnh nhất để tạo ra kết quả cuối cùng. Nếu có sự giống nhau giữa các mô hình<span class="calibre2">,  chúng</span> ta sẽ biết kết quả đầu ra là chính xác. </p>
	<p class="block_5">Cây quyết định (Decision Tree) là cái gì?</p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Một cây quyết định (Decision Tree) là một cấu trúc giúp chúng ta chia dữ liệu thành các nhánh <span class="calibre2">(  branches</span> ) và sau đó tạo một quyết định trên các cấp độ(level) khác nhau . Nó cho phép chúng ta đạt tới quyết định cuối cùng bằng cách đi xuống cái cây này . <b class="calibre1">Cây quyết định </b> là một sản phẩm của những thuật toán huấn luyện, những thứ định danh làm cách nào mà chúng ta chia dữ liệu một cách tốt nhất.</p>
	<p class="block_1">Mỗi quyết định được xử lý bắt đầu ở root node ở vị trí trên cùng của cái cây quyết định. Mỗi điểm (node) ở trên cây cơ bản là một quy tắc quyết định ( decision rule ). Các thuật toán xây dựng nên các quy tắc này dựa trên mối quan hệ giữa dữ liệu đầu vào (input data) và những nhãn đích trong dữ liệu đào tạo. Những giá trị trong dữ liệu đầu vào được sử dụng tận dụng để dự đoán kết quả cho giá trị đầu ra.</p>
	<p class="block_1">Bây giờ thì tạm hiểu khái niệm cơ bản về <b class="calibre1">Cây quyết định </b>, Cái tiếp theo cần hiểu là làm thế nào để những cái cây đó tự động được xây dựng ( tự mọc ). Chúng ta cần những thuật toán có thể xây dựng một cái cây tối ưu dựa trên dữ liệu của chúng ta. Để hiểu điều này chúng ta cần hiểu khái niệm về entropy. Trong chủ đề này chúng ta nhắc đến đó là entropy thông tin không phải là entropy nhiệt động học trong vật lý. Entropy cơ bản là một cái thước đo của sự không chắc chắn. Một trong những mục tiêu chính của <b class="calibre1">Cây quyết định </b>là sự giảm thiểu những thứ không chắc chắn khi chúng ta di chuyển từ root node (điểm gốc) tới những điểm khác (leaf nodes). Khi chúng ta nhìn thấy những điểm dữ liệu không biết, chúng ta hoàn toàn không thể chắc chắn về kết quả đầu ra. Khi chúng ta tới các nút, điểm lá (leaf node) chúng ta phải biết được kết quả đầu ra. điều này có nghĩa là chúng ta cần xây dựng một <b class="calibre1">Cây quyết định </b>theo một cách là giảm thiểu những dữ liệu không biết theo các cấp độ khác nhau. điều này có nghĩa là chúng ta cần giảm số entropy khi chúng ta di chuyển dần xuống cây dữ liệu.</p>
	<p class="block_7"><img src="images/000009.png" alt="2 tree" class="calibre3" /></p>
	<p class="block_8"><span class="text_">Một cây dữ liệu cơ bản lấy từ website: </span><a class="text_1" href="https://prateekvjoshi.com/">https://prateekvjoshi.com/</a></p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Túm cái vái lại là <b class="calibre1">Cây quyết định </b>là một một mô hình học máy có dạng như một cái cây. Mỗi nhánh không có lá trên cái cây này là một điểm quyết định, những điểm khác gọi là điểm quyết định. Mỗi điểm đưa ra một thử nghiệm cụ thể để xác định nơi đến tiếp theo. Dựa trên những kết quả đầu ra chúng ta sẽ đưa ra quyết định đi theo hướng trái hay phải của cái cây. Mô hình <b class="calibre1">Cây quyết định </b> phía bên trên là một bài toán dự đoán xem trời có mưa hay không dựa trên 3 tham số cơ bản là nhiệt độ,tốc độ gió,và độ ẩm.</p>
	<p class="block_1">Để xây dựng một mô hình cây quyết định một cách tự động thì thật sự là một thủ thuật… hiểu khái niệm về cái cây này thì rất dễ. nhưng xây dựng được một cây tốt ưu lại còn tự động nữa thì ….. Làm sao biết nó là tối ưu, lấy thuộc tính nào làm root node? làm sao chúng ta quyết định được các ngưỡng… đó là entropy nhưng làm sao để đo được entropy ??? ta<span class="calibre2"> có hàm số sau để đo entropy      </span></p>
	<p class="block_1"><span class="calibre2">    </span></p>
	<p class="block_9">Làm sao để giảm số entropy ở <b class="calibre1">cây quyết định</b> ? </p>
	<p class="block_1">Hãy xem một ví dụ với bộ dữ liệu (dataset) với 60 mục trong đó mục đầu tiên xuất hiện 14 lần mục thứ 2 xuất hiện 27 lần và mục thứ 3 xuất hiện 19 lần thay vào hàm số entropy bên trên ta có:</p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Trong một cây quyết định, chúng ta cần chia bộ dữ liệu thành 2 đường và giảm số entropy. đây là kết quả sau khi chúng ta chia bộ dữ liệu:</p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Giờ thì đo đạc kết quả entropy thế nào</p>
	<div class="frame_"><p class="block_10">left entropy = - (5/37)log(5/37) - (21/37)log(21/37) - (11/37)log(11/37) = 1.374 </p><p class="block_11">right entropy = - (9/23)log(9/23) - (6/23)log(6/23) - (8/23)log(8/23) = 1.565<span class="tab">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p></div>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Để đo lường kết quả tổng thể entropy của 2 nhánh nhỏ. Chúng ta cầ<span class="calibre2">n lấy tổng số dựa trên số lượng mục trên mỗi nhánh.  </span>bên trên ta coi nhánh trái có 37 mục và bên phải có 23 mục (items).</p>
	<p class="block_12">(kết quả tổng thể) overall entropy = (37/60)*1.374 + (23/60)*1.565 = 1.447</p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">xem thử kết quả khác nhau giữa số entropy ban đầu và số entropy tổng thể ta vừa tính</p>
	<p class="block_12">information gain = 1.537 - 1.447 = 0.09</p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">information gain là kết quả thông tin ta thu được nếu chia dữ liệu theo cách trên. Ở mỗi điểm chúng ta lặp lại việc này và lấy điểm thông tin thu được cao nhất.</p>
	<p class="block_13"><b class="calibre1">Xây dựng một phân loại Cây quyết định </b>( Decision Tree classifier)</p>
	<p class="block_1">Giờ thì mở PyCharm lên và tạo một file Python nào:</p>
	<p class="block_6">&nbsp;</p>
	<p class="block_14"><span class="text_2"># import package<br class="calibre4" /></span><span class="text_3">import </span><span class="text_4">numpy </span><span class="text_3">as </span><span class="text_4">np<br class="calibre4" /></span><span class="text_3">import </span><span class="text_4">matplotlib.pyplot </span><span class="text_3">as </span><span class="text_4">plt<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.metrics </span><span class="text_3">import </span><span class="text_4">classification_report<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn </span><span class="text_3">import </span><span class="text_4">model_selection<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.tree </span><span class="text_3">import </span><span class="text_4">DecisionTreeClassifier<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">utilities </span><span class="text_3">import </span><span class="text_4">visualize_classifier<br class="calibre4" /></span><span class="text_2"># Chúng ta xử dụng dữ liệu trong file data_decision_trees.txt . Trong file này dữ liệu ở mỗi dòng được tách bởi dấu [,]. 2 giá trị đầu tiên tương ứng với dữ liệu vào(input data) và giá trị cuối cùng tương ứng là nhãn đích (target label).<br class="calibre4" /></span><span class="text_4">input_file=</span><span class="text_5">"data/data_decision_trees.txt"<br class="calibre4" /></span><span class="text_4">data=np.loadtxt(input_file</span><span class="text_3">,</span><span class="text_6">delimiter</span><span class="text_4">=</span><span class="text_5">','</span><span class="text_4">)<br class="calibre4" />X</span><span class="text_3">,</span><span class="text_4">y=data[:</span><span class="text_3">,</span><span class="text_4">:-</span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">data[:</span><span class="text_3">,</span><span class="text_4">-</span><span class="text_7">1</span><span class="text_4">]<br class="calibre4" /></span><span class="text_2"># Tách dữ liệu thành 2 lớp dựa trên nhãn của chúng<br class="calibre4" /></span><span class="text_4">class_0=np.array(X[y==</span><span class="text_7">0</span><span class="text_4">])<br class="calibre4" />class_1=np.array(X[y==</span><span class="text_7">1</span><span class="text_4">])<br class="calibre4" /></span><span class="text_2"># Xem thử dữ liệu nhập xử dụng scatter plot của plt:<br class="calibre4" /></span><span class="text_4">plt.figure()<br class="calibre4" />plt.scatter(class_0[:</span><span class="text_3">,</span><span class="text_7">0</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">class_0[:</span><span class="text_3">,</span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_6">s</span><span class="text_4">=</span><span class="text_7">75</span><span class="text_3">,</span><span class="text_6">facecolors</span><span class="text_4">=</span><span class="text_5">'gray'</span><span class="text_3">,</span><span class="text_6">edgecolors</span><span class="text_4">=</span><span class="text_5">'gray'</span><span class="text_3">,</span><span class="text_6">linewidth</span><span class="text_4">=</span><span class="text_7">1</span><span class="text_3">,</span><span class="text_6">marker</span><span class="text_4">=</span><span class="text_5">'x'</span><span class="text_4">)<br class="calibre4" />plt.scatter(class_1[:</span><span class="text_3">, </span><span class="text_7">0</span><span class="text_4">]</span><span class="text_3">, </span><span class="text_4">class_1[:</span><span class="text_3">, </span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">, </span><span class="text_6">s</span><span class="text_4">=</span><span class="text_7">75</span><span class="text_3">, </span><span class="text_6">facecolors</span><span class="text_4">=</span><span class="text_5">'white'</span><span class="text_3">, </span><span class="text_6">edgecolors</span><span class="text_4">=</span><span class="text_5">'black'</span><span class="text_3">, </span><span class="text_6">linewidth</span><span class="text_4">=</span><span class="text_7">1</span><span class="text_3">, </span><span class="text_6">marker</span><span class="text_4">=</span><span class="text_5">'o'</span><span class="text_4">)<br class="calibre4" />plt.title(</span><span class="text_5">'Dữ liệu nhập'</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># Chúng ta cần chia dữ liệu vào trong tập dữ liệu để train và test<br class="calibre4" /></span><span class="text_4">X_train</span><span class="text_3">,</span><span class="text_4">X_test</span><span class="text_3">,</span><span class="text_4">y_train</span><span class="text_3">,</span><span class="text_4">y_test = model_selection.train_test_split(X</span><span class="text_3">,</span><span class="text_4">y</span><span class="text_3">,</span><span class="text_6">test_size</span><span class="text_4">=</span><span class="text_7">0.25</span><span class="text_3">,</span><span class="text_6">random_state</span><span class="text_4">=</span><span class="text_7">5</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"><span class="calibre5"># Tạo xây dựng và biểu diễn phân loại Cây Quyết định  dựa trên tập dữ liệu. tham số random_state chỉ đến số hạt giống được sử dụng bởi những số ngẫu nhiên cần thiết được tạo rađể khởi tạo cho thuật toán phân loại Cây Quyết Định. Tham số max_depth chỉ ra "độ cao" của cây quyết định mà chúng ta muốn xây dựng:</span></span><span class="text_2"><br class="calibre4" /></span><span class="text_4">params={</span><span class="text_5">'random_state'</span><span class="text_4">:</span><span class="text_7">0</span><span class="text_3">,</span><span class="text_5">'max_depth' </span><span class="text_4">:</span><span class="text_7">4</span><span class="text_4">}<br class="calibre4" />classifier=DecisionTreeClassifier(**params)<br class="calibre4" />classifier.fit(X_train</span><span class="text_3">,</span><span class="text_4">y_train)<br class="calibre4" />visualize_classifier(classifier</span><span class="text_3">,</span><span class="text_4">X_train</span><span class="text_3">,</span><span class="text_4">y_train</span><span class="text_3">,</span><span class="text_5">'Tập dữ liệu train'</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># tính dữ liệu đầu ra trên phép phân loại dựa trên tập dữ liệu và biểu diễn nó:<br class="calibre4" /></span><span class="text_4">y_test_pred=classifier.predict(X_test)<br class="calibre4" />visualize_classifier(classifier</span><span class="text_3">,</span><span class="text_4">X_test</span><span class="text_3">,</span><span class="text_4">y_test</span><span class="text_3">,</span><span class="text_5">"Tập dữ liệu test"</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># Đánh giá hiệu suất của phép phân loại bằng cách in báo cáo của phép phân loại<br class="calibre4" /></span><span class="text_4">class_names=[</span><span class="text_5">'Class-0'</span><span class="text_3">,</span><span class="text_5">'Class-1'</span><span class="text_4">]<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5">"</span><span class="text_4">+</span><span class="text_5">"#"</span><span class="text_4">*</span><span class="text_7">40</span><span class="text_4">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5"> Đánh giá hiệu suất phân loại trên Tập dữ liệu train</span><span class="text_3">\n</span><span class="text_5">"</span><span class="text_4">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(classification_report(y_train</span><span class="text_3">,</span><span class="text_4">classifier.predict(X_train)</span><span class="text_3">,</span><span class="text_6">target_names</span><span class="text_4">=class_names))<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"#"</span><span class="text_4">*</span><span class="text_7">40</span><span class="text_4">+</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5">"</span><span class="text_4">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"#"</span><span class="text_4">*</span><span class="text_7">40</span><span class="text_4">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5"> Hiệu suất phân loại trên Tập dữ test</span><span class="text_3">\n</span><span class="text_5">"</span><span class="text_4">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(classification_report(y_test</span><span class="text_3">,</span><span class="text_4">y_test_pred</span><span class="text_3">,</span><span class="text_6">target_names</span><span class="text_4">=class_names))<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"#"</span><span class="text_4">*</span><span class="text_7">40</span><span class="text_4">+</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5">"</span><span class="text_4">)<br class="calibre4" />plt.show()</span></p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Chạy code trên với PyCharm bạn sẽ thấy nó hiện lên 2 Biểu đồ như sau.</p>
	<p class="block_7"><img src="images/000014.png" alt="Image" class="calibre6" /></p>
	<p class="block_7">1.0 Biểu đồ này biểu diễn dữ liệu nhập</p>
	<p class="block_7"><img src="images/000016.png" alt="Image" class="calibre6" /></p>
	<p class="block_7">2.0 Biểu đồ này thể hiện ranh giới phân loại dựa trên tập dữ liệu test</p>
	<p class="block_7"><img src="images/000017.png" alt="Image" class="calibre6" /></p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Và sau đây là output được in ra ở Terminal:</p>
	<p class="block_15">########################################</p>
	<p class="block_16"> Đánh giá hiệu suất phân loại trên Tập dữ liệu train</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">              </span></span><span class="text_9">precision<span class="calibre5">    recall  f1-score   support</span></span></p>
	<p class="block_16"><span class="calibre5">     Class-0       0.99      1.00      1.00       137</span></p>
	<p class="block_16"><span class="calibre5">     Class-1       1.00      0.99      1.00       133</span></p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">micro<span class="calibre5"> avg       1.00      1.00      1.00       270</span></span></p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">macro<span class="calibre5"> avg       1.00      1.00      1.00       270</span></span></p>
	<p class="block_16">weighted<span class="calibre5"> avg       1.00      1.00      1.00       270</span></p>
	<p class="block_16">########################################</p>
	<p class="block_16">########################################</p>
	<p class="block_16"> Hiệu suất phân loại trên Tập dữ test</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">              </span></span><span class="text_9">precision<span class="calibre5">    recall  f1-score   support</span></span></p>
	<p class="block_16"><span class="calibre5">     Class-0       0.93      1.00      0.97        43</span></p>
	<p class="block_16"><span class="calibre5">     Class-1       1.00      0.94      0.97        47</span></p>
	<p class="block_18">&nbsp;</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">micro<span class="calibre5"> avg       0.97      0.97      0.97        90</span></span></p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">macro<span class="calibre5"> avg       0.97      0.97      0.97        90</span></span></p>
	<p class="block_16">weighted<span class="calibre5"> avg       0.97      0.97      0.97        90</span></p>
	<p class="block_19">&nbsp;</p>
	<p class="block_1">Nhìn vào phần output trên terminal bạn có thể thấy một Hiệu suất của phép phân loại được biểu hiện bởi (Precision(độ chính xác),recall(triệu hồi …hồi tưởng méo biết là cái giề), và f1-scores ( điểm f1). Độ chính xác chỉ ra tính chính xác và recall là số lượng phần tử (items) được lấy theo tỷ lệ phần tram của tổng số items. Một bộ phân loại tốt sẽ có điểm Precision(độ chính xác),recall cao. nhưng thường phải đánh đổi giữa hai số này. Vì thế chúng ta có chỉ số <i class="calibre7">f1-score </i>để tháy sự khác biệt. <i class="calibre7">F1-Score </i> là số trung bình của precision và recall, giúp cân bằng hai giá trị đó.</p>
	<p class="block_20">Random Forset và Extremly Random Forset là gì?</p>
	<p class="block_1">Một Random Forset là một trường hợp cụ thể của học độc lập (Ensemble learning) mà mô hình (models) được xây dựng bang Cây Quyết Định (Decision Tree). Nhóm cây quyết định này sau đó được sử dụng để dự đoán kết quả đầu ra. Chúng ta sử dụng một tập con ngẫu nhiên (random subset) của dữ liệu đào tạo (training data) để xây dựng lên mỗi Cây quyết định (Decision Tree). Điều này đảm bảo tính đa dạng giữa các <i class="calibre7">cây quyết định </i> khác nhau. Trong phần đầu tiên, chúng ta sẽ thảo luận về một trong những thứ quan trọng nhất trong ensemble learning là đảm bảo sự đa dạng của các mô hình cá nhân.</p>
	<p class="block_1">Một trong những thứ quan trọng về Random Forest là chúng không overfit. Như chúng ta đã biết, overfitting là vấn đề chúng ta thường phải gặp trong ML. Bằng cách xây dựng một bộ cây quyết định (Decision Trees) sử dụng nhiều tập hợp dữ liệu con khác nhau, chúng ta đảm bảo những mô hình đó không overfit dữ liệu đào tạo. Trong suốt quá trình xây dựng lên cái cây, những điểm (nodes) được chia ra liên tiếp điểm ngưỡng tốt nhất được chọn để giảm số <i class="calibre7">entropy </i>theo mỗi mức độ. Các điểm chia không xem xét tất cả các tính năng, đặc điểm trong bộ dữ liệu đầu vào, thay vì thế nó chọn sự phân chia tốt nhất trong số ngẫu nhiên các tập dữ liệu của các tính năng được xem xét. Vì thế tính ngẫu nhiên có xu hướng làm tăng độ lệch (số bias) của một Random Forset, nhưng phương sai giảm ( số variance) bởi tính trung bình. Vì thế chúng ta sẽ kết thúc với một mô hình mạnh.</p>
	<p class="block_1"><b class="calibre1">Entremely Random Forest </b> lấy ngẫu nhiên trên level tiếp theo, cùng với việc lấy ngẫu nhiên các tập tính năng(features), hạn mức, mức ngưỡng (thresholds) cũng được chọn ngẫu nhiên. Các mức ngẫu nhiên được tạo ra và chọn làm quy tắc chia,tách. Và làm giảm phương sai (variance) của phương trình mo hình. Vì thế vùng biên chọn sử dụng <b class="calibre1">Extremely Random Forest </b>có xu hướng chuẩn hơn là sử dụng một cái <b class="calibre1">Random Forest.</b></p>
	<p class="block_20">Xây dựng một bộ phân loại sử dụng Random Forests và Extremely Random Forests</p>
	<p class="block_1">Bây giờ thì chúng ta thử xây dựng một bộ phân loại dựa trên Random Forests và Extremely Random Forests. Cách xây dựng 2 bộ phân loại trên rất giống nhau, vậy nên chúng ta sẽ xử dụng một bộ đầu vào được chỉ định cần thiết để xây dựng.</p>
	<p class="block_1">Tạo một File Python mới và bắt đầu:</p>
	<p class="block_14"><span class="text_3">import </span><span class="text_4">argparse<br class="calibre4" /><br class="calibre4" /></span><span class="text_3">import </span><span class="text_4">numpy </span><span class="text_3">as </span><span class="text_4">np<br class="calibre4" /></span><span class="text_3">import </span><span class="text_4">matplotlib.pyplot </span><span class="text_3">as </span><span class="text_4">plt<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.metrics </span><span class="text_3">import </span><span class="text_4">classification_report<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn </span><span class="text_3">import </span><span class="text_4">model_selection<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.ensemble </span><span class="text_3">import </span><span class="text_4">RandomForestClassifier</span><span class="text_3">, </span><span class="text_4">ExtraTreesClassifier<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">utilities </span><span class="text_3">import </span><span class="text_4">visualize_classifier<br class="calibre4" /><br class="calibre4" /></span><span class="text_2"># Định nghĩa một đối số phân tích cho Python để chúng ta có thể lấy kiểu phân loại như là một tham số đầu vào. Dựa trên tham số này chúng ta có thể xây dựng một bộ phân loại Random Forest hoặc một bộ phân loại Extremely Random Forests<br class="calibre4" /></span><span class="text_3">def </span><span class="text_10">build_arg_parser</span><span class="text_4">():<br class="calibre4" /><span class="calibre5">    parser=argparse.ArgumentParser(</span></span><span class="text_6">description</span><span class="text_4">=</span><span class="text_5">'Classify data using Enxemble Learning Techniques'</span><span class="text_4">)<br class="calibre4" /><span class="calibre5">    parser.add_argument(</span></span><span class="text_5">'--classifier-type'</span><span class="text_3">,</span><span class="text_6">dest</span><span class="text_4">=</span><span class="text_5">'classifier_type'</span><span class="text_3">,</span><span class="text_6">required</span><span class="text_4">=</span><span class="text_3">True,</span><span class="text_6">choices</span><span class="text_4">=[</span><span class="text_5">'rf'</span><span class="text_3">,</span><span class="text_5">'erf'</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_6">help</span><span class="text_4">=</span><span class="text_5">"Type of classifier to use can be either 'rf' or 'erf'"</span><span class="text_4">)<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_3">return </span><span class="text_4">parser<br class="calibre4" /></span><span class="text_2"># Định nghĩa hàm Main và parser tham số đầu vào<br class="calibre4" /></span><span class="text_3">if </span><span class="text_4">__name__==</span><span class="text_5">'__main__'</span><span class="text_4">:<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_2"># Parser tham số đầu vào<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_4">args=build_arg_parser().parse_args()<br class="calibre4" /><span class="calibre5">    classifier_type=args.classifier_type</span></span><span class="text_4"><br class="calibre4" /></span><span class="text_2"># Chúng ta sẽ xử dụng dữ liệu từ file data/data_random_forest.txt. Mỗi dòng trong file này sẽ có một dấu phẩy để phân chia các giá trị. Hai giá trị đầu tiên tương ứng là giá trị đầu vào ,và giá trị cưới cùng tương ứng là nhãn đích. Chúng ta có 3 lớp khác biệt trong tập dũ liệu này.<br class="calibre4" /># Load input data<br class="calibre4" /></span><span class="text_4">input_file=</span><span class="text_5">'data/data_random_forests.txt'<br class="calibre4" /></span><span class="text_4">data=np.loadtxt(input_file</span><span class="text_3">,</span><span class="text_6">delimiter</span><span class="text_4">=</span><span class="text_5">","</span><span class="text_4">)<br class="calibre4" />X</span><span class="text_3">,</span><span class="text_4">y=data[:</span><span class="text_3">,</span><span class="text_4">:-</span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">data[:</span><span class="text_3">,</span><span class="text_4">-</span><span class="text_7">1</span><span class="text_4">]<br class="calibre4" /></span><span class="text_2"># Tách dữ liệu đầu vào thành 3 lớp<br class="calibre4" /></span><span class="text_4">class_0=np.array(X[y==</span><span class="text_7">0</span><span class="text_4">])<br class="calibre4" />class_1=np.array(X[y==</span><span class="text_7">1</span><span class="text_4">])<br class="calibre4" />class_2=np.array(X[y==</span><span class="text_7">2</span><span class="text_4">])<br class="calibre4" /></span><span class="text_2"># In dữ liệu đầu vào lên biểu đồ<br class="calibre4" /></span><span class="text_4">plt.figure()<br class="calibre4" />plt.scatter(class_0[:</span><span class="text_3">,</span><span class="text_7">0</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">class_0[:</span><span class="text_3">,</span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_6">s</span><span class="text_4">=</span><span class="text_7">75</span><span class="text_3">,</span><span class="text_6">facecolors</span><span class="text_4">=</span><span class="text_5">"white"</span><span class="text_3">,</span><span class="text_6">edgecolors</span><span class="text_4">=</span><span class="text_5">"black"</span><span class="text_3">,</span><span class="text_6">linewidths</span><span class="text_4">=</span><span class="text_7">1</span><span class="text_3">,</span><span class="text_6">marker</span><span class="text_4">=</span><span class="text_5">'s'</span><span class="text_4">)<br class="calibre4" />plt.scatter(class_1[:</span><span class="text_3">,</span><span class="text_7">0</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">class_1[:</span><span class="text_3">,</span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_6">s</span><span class="text_4">=</span><span class="text_7">75</span><span class="text_3">,</span><span class="text_6">facecolors</span><span class="text_4">=</span><span class="text_5">"black"</span><span class="text_3">,</span><span class="text_6">edgecolors</span><span class="text_4">=</span><span class="text_5">"black"</span><span class="text_3">,</span><span class="text_6">linewidths</span><span class="text_4">=</span><span class="text_7">1</span><span class="text_3">,</span><span class="text_6">marker</span><span class="text_4">=</span><span class="text_5">'o'</span><span class="text_4">)<br class="calibre4" />plt.scatter(class_2[:</span><span class="text_3">,</span><span class="text_7">0</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">class_2[:</span><span class="text_3">,</span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_6">s</span><span class="text_4">=</span><span class="text_7">75</span><span class="text_3">,</span><span class="text_6">facecolors</span><span class="text_4">=</span><span class="text_5">"gray"</span><span class="text_3">,</span><span class="text_6">edgecolors</span><span class="text_4">=</span><span class="text_5">"black"</span><span class="text_3">,</span><span class="text_6">linewidths</span><span class="text_4">=</span><span class="text_7">1</span><span class="text_3">,</span><span class="text_6">marker</span><span class="text_4">=</span><span class="text_5">'^'</span><span class="text_4">)<br class="calibre4" />plt.title(</span><span class="text_5">" Dữ liệu đầu vào "</span><span class="text_4">)<br class="calibre4" /><br class="calibre4" /></span><span class="text_2"># Chia dữ liệu vào trong tập training và testing (split the data into training and testing datasets):<br class="calibre4" /></span><span class="text_4">X_train</span><span class="text_3">,</span><span class="text_4">X_test</span><span class="text_3">,</span><span class="text_4">y_train</span><span class="text_3">,</span><span class="text_4">y_test=model_selection.train_test_split(X</span><span class="text_3">,</span><span class="text_4">y</span><span class="text_3">,</span><span class="text_6">test_size</span><span class="text_4">=</span><span class="text_7">0.25</span><span class="text_3">,</span><span class="text_6">random_state</span><span class="text_4">=</span><span class="text_7">5</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2">#Định nghĩa tham số để sử dụng khi chúng ta xây dựng bộ phân loại. tham số n_estimators chỉ ra số cây (trees) chúng ta sẽ xây dựng, và tham số max_depth là số bậc (level) trên mỗi cây. Tham số random_state là số hạt giống (seed) của số ngẫu nhiên cần thiết để khởi tạo một thuật toán phân loại Random Forest<br class="calibre4" /># Ensemble Learning classifier<br class="calibre4" /></span><span class="text_4">params={</span><span class="text_5">'n_estimators'</span><span class="text_4">:</span><span class="text_7">100</span><span class="text_3">,</span><span class="text_5">'max_depth'</span><span class="text_4">:</span><span class="text_7">4</span><span class="text_3">,</span><span class="text_5">'random_state'</span><span class="text_4">:</span><span class="text_7">0</span><span class="text_4">}<br class="calibre4" /></span><span class="text_2">#Dựa trên tham số đầu vào, chúng ta cũng xây dựng một Bộ phân loại Random Forests hoặc một Extremely Random Forest classifier<br class="calibre4" /></span><span class="text_3">if </span><span class="text_4">classifier_type==</span><span class="text_5">'rf'</span><span class="text_4">:<br class="calibre4" /><span class="calibre5">    classifier=RandomForestClassifier(**params)</span></span><span class="text_4"><br class="calibre4" /></span><span class="text_3">else</span><span class="text_4">:<br class="calibre4" /><span class="calibre5">    classifier=ExtraTreesClassifier(**params)</span></span><span class="text_4"><br class="calibre4" /></span><span class="text_2"># Train và hiển thị bộ phân loại ra màn hình:<br class="calibre4" /></span><span class="text_4">classifier.fit(X_train</span><span class="text_3">,</span><span class="text_4">y_train)<br class="calibre4" />visualize_classifier(classifier</span><span class="text_3">,</span><span class="text_4">X_train</span><span class="text_3">,</span><span class="text_4">y_train</span><span class="text_3">,</span><span class="text_5">"Bộ dữ liệu training(training dataset)"</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># Tính toán (dự đoán) kết quả đầu ra dựa trên bộ dữ liệu test và hiển thị ra màn hình:<br class="calibre4" /></span><span class="text_4">y_test_pred=classifier.predict(X_test)<br class="calibre4" />visualize_classifier(classifier</span><span class="text_3">,</span><span class="text_4">X_test</span><span class="text_3">,</span><span class="text_4">y_test</span><span class="text_3">,</span><span class="text_5">"Bộ dữ liệu testing(testing dataset)"</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># Đánh giá hiệu suất của phép phân loại bằng cách print report<br class="calibre4" /></span><span class="text_4">class_names=[</span><span class="text_5">'Class-0'</span><span class="text_3">,</span><span class="text_5">'Class-1'</span><span class="text_3">,</span><span class="text_5">'Class-2'</span><span class="text_4">]<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5">"</span><span class="text_3">,</span><span class="text_5">"#"</span><span class="text_4">*</span><span class="text_7">44</span><span class="text_4">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5"> Hiệu suất phân loại trên dữ liệu training (training dataset)"</span><span class="text_4">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(classification_report(y_train</span><span class="text_3">,</span><span class="text_4">classifier.predict(X_train)</span><span class="text_3">,</span><span class="text_6">target_names</span><span class="text_4">=class_names))<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"#"</span><span class="text_4">*</span><span class="text_7">44</span><span class="text_3">,</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5">"</span><span class="text_4">)<br class="calibre4" /><br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5">"</span><span class="text_3">,</span><span class="text_5">"*"</span><span class="text_4">*</span><span class="text_7">44</span><span class="text_4">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5"> Hiệu suất phân loại trên dữ liệu testing(testing dataset)"</span><span class="text_4">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(classification_report(y_test</span><span class="text_3">,</span><span class="text_4">y_test_pred</span><span class="text_3">,</span><span class="text_6">target_names</span><span class="text_4">=class_names))<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"*"</span><span class="text_4">*</span><span class="text_7">40</span><span class="text_4">)</span></p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Lưu file python trên dưới tên random_forest.py và chạy file đó trong terminal với tham số<i class="calibre7"> --classifier-types rf như sau:</i></p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Ta có kết quả sau</p>
	<p class="block_21"><img src="images/000000.png" alt="Image" class="calibre8" /></p>
	<p class="block_22">Figure 1 Dữ liệu đầu vào</p>
	<p class="block_7"><img src="images/000013.png" alt="Image" class="calibre9" /><img src="images/000012.png" alt="Image" class="calibre10" /></p>
	<p class="block_23"><i class="calibre11"><span class="calibre5">Hình  </span></i><i class="calibre11">1 Dữ liệu training với tham số rf</i></p>
	<p class="block_23"><i class="calibre11"><span class="calibre5">Hình  </span></i><i class="calibre11">1 Dữ liệu training với tham số rf</i></p>
	<p class="block_23"><i class="calibre11"><span class="calibre5">Hình  </span></i><i class="calibre11">2 Bộ dữ liệu train với tham số erf</i></p>
	<p class="block_23"><i class="calibre11"><span class="calibre5">Hình  </span></i><i class="calibre11">2 Bộ dữ liệu train với tham số erf</i></p>
	<p class="block_21"> <img src="images/000001.png" alt="Image" class="calibre9" /> <img src="images/000002.png" alt="Image" class="calibre12" /></p>
	<p class="block_22">1 Dữ liệu test với tham số rf</p>
	<p class="block_22">1 Dữ liệu test với tham số rf</p>
	<p class="block_22">2 Dữ liệu test với tham số erf</p>
	<p class="block_24">&nbsp;</p>
	<p class="block_20">Output ở Terminal tham số rf:</p>
	<p class="block_15">############################################</p>
	<p class="block_16"> Hiệu suất phân loại trên dữ liệu training (training dataset)</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">              </span></span><span class="text_9">precision<span class="calibre5">    recall  f1-score   support</span></span></p>
	<p class="block_16"><span class="calibre5">     Class-0       0.91      0.86      0.88       221</span></p>
	<p class="block_16"><span class="calibre5">     Class-1       0.84      0.87      0.86       230</span></p>
	<p class="block_16"><span class="calibre5">     Class-2       0.86      0.87      0.86       224</span></p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">micro<span class="calibre5"> avg       0.87      0.87      0.87       675</span></span></p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">macro<span class="calibre5"> avg       0.87      0.87      0.87       675</span></span></p>
	<p class="block_16">weighted<span class="calibre5"> avg       0.87      0.87      0.87       675</span></p>
	<p class="block_16">############################################ </p>
	<p class="block_16"> ********************************************</p>
	<p class="block_16"> Hiệu suất phân loại trên dữ liệu testing(testing dataset)</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">              </span></span><span class="text_9">precision<span class="calibre5">    recall  f1-score   support</span></span></p>
	<p class="block_16"><span class="calibre5">     Class-0       0.92      0.85      0.88        79</span></p>
	<p class="block_16"><span class="calibre5">     Class-1       0.86      0.84      0.85        70</span></p>
	<p class="block_16"><span class="calibre5">     Class-2       0.84      0.92      0.88        76</span></p>
	<p class="block_18">&nbsp;</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">micro<span class="calibre5"> avg       0.87      0.87      0.87       225</span></span></p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">macro<span class="calibre5"> avg       0.87      0.87      0.87       225</span></span></p>
	<p class="block_16">weighted<span class="calibre5"> avg       0.87      0.87      0.87       225</span></p>
	<p class="block_25">****************************************</p>
	<p class="block_20">Output Terminal Tham số erf:</p>
	<p class="block_15">############################################</p>
	<p class="block_16"> Hiệu suất phân loại trên dữ liệu training (training dataset)</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">              </span></span><span class="text_9">precision<span class="calibre5">    recall  f1-score   support</span></span></p>
	<p class="block_16"><span class="calibre5">     Class-0       0.89      0.83      0.86       221</span></p>
	<p class="block_16"><span class="calibre5">     Class-1       0.82      0.84      0.83       230</span></p>
	<p class="block_16"><span class="calibre5">     Class-2       0.83      0.86      0.85       224</span></p>
	<p class="block_18">&nbsp;</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">micro<span class="calibre5"> avg       0.85      0.85      0.85       675</span></span></p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">macro<span class="calibre5"> avg       0.85      0.85      0.85       675</span></span></p>
	<p class="block_16">weighted<span class="calibre5"> avg       0.85      0.85      0.85       675</span></p>
	<p class="block_16">############################################ </p>
	<p class="block_18">&nbsp;</p>
	<p class="block_18">&nbsp;</p>
	<p class="block_16"> ********************************************</p>
	<p class="block_16"> Hiệu suất phân loại trên dữ liệu testing(testing dataset)</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">              </span></span><span class="text_9">precision<span class="calibre5">    recall  f1-score   support</span></span></p>
	<p class="block_18">&nbsp;</p>
	<p class="block_16"><span class="calibre5">     Class-0       0.92      0.85      0.88        79</span></p>
	<p class="block_16"><span class="calibre5">     Class-1       0.84      0.84      0.84        70</span></p>
	<p class="block_16"><span class="calibre5">     Class-2       0.85      0.92      0.89        76</span></p>
	<p class="block_18">&nbsp;</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">micro<span class="calibre5"> avg       0.87      0.87      0.87       225</span></span></p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">macro<span class="calibre5"> avg       0.87      0.87      0.87       225</span></span></p>
	<p class="block_16">weighted<span class="calibre5"> avg       0.87      0.87      0.87       225</span></p>
	<p class="block_18">&nbsp;</p>
	<p class="block_25">****************************************</p>
	<p class="block_1">Để thêm tham số khi run file trong PyCharm bạn phải edit trong configuartions như sau </p>
	<p class="block_1"><img src="images/000006.png" alt="Image" class="calibre13" /></p>
	<p class="block_1">Chúng ta xét 2 hình output bên cạnh nhau khi thay đổi tham số rf và erf ta cố thể thấy đường viền bao quanh bởi Extremely Random Forest tốt hơn là RandomForest.</p>
	<p class="block_20">Ước tính độ tin cậy của một dự đoán</p>
	<p class="block_1">Hãy quan sát các đầu ra thu được ở Terminal, bạn sẽ thấy xác suất được in ra ở mỗi điểm dữ liệu. Những xác suất đó được sử dụng như giá trị để đo độ tin cậy của mỗi lớp. Ước tính giá trị độ tin cậy là một nhiệm vụ rất quan trọng trong Machine Learning. Trong cùng một file python bên trên ta thêm vài dòng để tính toán độ tin cậy của mô hình:</p>
	<div class="frame_"><p class="block_10"># Tính toán độ tin cậy của một mô hình</p><p class="block_26"><span class="text_4">#định nghĩa một array của test data points:<br class="calibre4" /></span><span class="text_11">test_datapoints=np.array([[</span><span class="text_7">5</span><span class="text_3">,</span><span class="text_7">5</span><span class="text_11">]</span><span class="text_3">,</span><span class="text_11">[</span><span class="text_7">3</span><span class="text_3">,</span><span class="text_7">6</span><span class="text_11">]</span><span class="text_3">,</span><span class="text_11">[</span><span class="text_7">6</span><span class="text_3">,</span><span class="text_7">4</span><span class="text_11">]</span><span class="text_3">,</span><span class="text_11">[</span><span class="text_7">7</span><span class="text_3">,</span><span class="text_7">2</span><span class="text_11">]</span><span class="text_3">,</span><span class="text_11">[</span><span class="text_7">4</span><span class="text_3">,</span><span class="text_7">4</span><span class="text_11">]</span><span class="text_3">,</span><span class="text_11">[</span><span class="text_7">5</span><span class="text_3">,</span><span class="text_7">2</span><span class="text_11">]])<br class="calibre4" /></span><span class="text_4"><span class="calibre5"># Object classifier  là một phương thức được xây dựng sẵn để tính toán độ tin cậy. Hãy phân loại mỗi điểm và tính toán giá trị độ tin cậy:</span></span><span class="text_4"><br class="calibre4" /></span><span class="text_8">print</span><span class="text_11">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5"> Thước đo độ tin cậy"</span><span class="text_11">)<br class="calibre4" /></span><span class="text_3">for </span><span class="text_11">datapoint </span><span class="text_3">in </span><span class="text_11">test_datapoints:<br class="calibre4" /><span class="calibre5">    probabilities=classifier.predict_proba([datapoint])[</span></span><span class="text_7">0</span><span class="text_11">]<br class="calibre4" /><span class="calibre5">    predicted_class=</span></span><span class="text_5">'Class-'</span><span class="text_11">+</span><span class="text_8">str</span><span class="text_11">(np.argmax(probabilities))<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_8">print</span><span class="text_11">(</span><span class="text_5">'</span><span class="text_3">\n</span><span class="text_5">DataPoint:'</span><span class="text_3">,</span><span class="text_11">datapoint)<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_8">print</span><span class="text_11">(</span><span class="text_5">'Predict Class:'</span><span class="text_3">,</span><span class="text_11">predicted_class)<br class="calibre4" /></span><span class="text_4"># In ra màn hình<br class="calibre4" /></span><span class="text_11">visualize_classifier(classifier</span><span class="text_3">,</span><span class="text_11">test_datapoints</span><span class="text_3">,</span><span class="text_11">[</span><span class="text_7">0</span><span class="text_11">]*</span><span class="text_8">len</span><span class="text_11">(test_datapoints)</span><span class="text_3">,</span><span class="text_5">"Kiểm tra điểm dữ liệu(Test datapoints)"</span><span class="text_11">)</span></p></div>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Chạy đoạn code trên với lần lượt 2 tham số là rf và erf ta sẽ có kết quả như sau ở terminal và hình output:</p>
	<p class="block_20"># Flag erf:</p>
	<p class="block_7"><img src="images/000005.png" alt="Image" class="calibre14" /></p>
	<p class="block_6">&nbsp;</p>
	<p class="block_15">Thước đo độ tin cậy</p>
	<p class="block_16"><span class="calibre5">Probabilities:  [0.48904419 0.28020114 0.23075467]</span></p>
	<p class="block_16">DataPoint: [5 5]</p>
	<p class="block_16">Predict Class: Class-0</p>
	<p class="block_16"><span class="calibre5">Probabilities:  [0.66707383 0.12424406 0.20868211]</span></p>
	<p class="block_16">DataPoint: [3 6]</p>
	<p class="block_16">Predict Class: Class-0</p>
	<p class="block_16"><span class="calibre5">Probabilities:  [0.25788769 0.49535144 0.24676087]</span></p>
	<p class="block_16">DataPoint: [6 4]</p>
	<p class="block_16">Predict Class: Class-1</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">Probabilities:  [0.10794013 </span></span><span class="text_9"><span class="calibre5">0.6246677  0.26739217</span></span><span class="text_9">]</span></p>
	<p class="block_16">DataPoint: [7 2]</p>
	<p class="block_16">Predict Class: Class-1</p>
	<p class="block_16"><span class="calibre5">Probabilities:  [0.33383778 0.21495182 0.45121039]</span></p>
	<p class="block_16">DataPoint: [4 4]</p>
	<p class="block_16">Predict Class: Class-2</p>
	<p class="block_16"><span class="calibre5">Probabilities:  [0.18671115 0.28760896 0.52567989]</span></p>
	<p class="block_16">DataPoint: [5 2]</p>
	<p class="block_25">Predict Class: Class-2</p>
	<p class="block_6">&nbsp;</p>
	<p class="block_27">#Flag rf</p>
	<p class="block_1"><img src="images/000003.png" alt="Image" class="calibre6" /></p>
	<p class="block_15">Thước đo độ tin cậy</p>
	<p class="block_16"><span class="calibre5">Probabilities:  [0.81427532 0.08639273 0.09933195]</span></p>
	<p class="block_16">DataPoint: [5 5]</p>
	<p class="block_16">Predict Class: Class-0</p>
	<p class="block_16"><span class="calibre5">Probabilities:  [0.93574458 0.02465345 0.03960197]</span></p>
	<p class="block_16">DataPoint: [3 6]</p>
	<p class="block_16">Predict Class: Class-0</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">Probabilities:  [0.12232404 </span></span><span class="text_9"><span class="calibre5">0.7451078  0.13256816</span></span><span class="text_9">]</span></p>
	<p class="block_16">DataPoint: [6 4]</p>
	<p class="block_16">Predict Class: Class-1</p>
	<p class="block_16"><span class="calibre5">Probabilities:  [0.05415465 0.70660226 0.23924309]</span></p>
	<p class="block_16">DataPoint: [7 2]</p>
	<p class="block_16">Predict Class: Class-1</p>
	<p class="block_16"><span class="calibre5">Probabilities:  [0.20594744 0.15523491 0.63881765]</span></p>
	<p class="block_16">DataPoint: [4 4]</p>
	<p class="block_16">Predict Class: Class-2</p>
	<p class="block_17"><span class="text_9"><span class="calibre5">Probabilities:  [0.05403583 </span></span><span class="text_9"><span class="calibre5">0.0931115  0.85285267</span></span><span class="text_9">]</span></p>
	<p class="block_16">DataPoint: [5 2]</p>
	<p class="block_25">Predict Class: Class-2</p>
	<p class="block_6">&nbsp;</p>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">Trên mỗi điểm dữ liệu nó sẽ tính toán số phần tram của điểm đó thuộc về lớp nào trong 3 lớp chúng ta đã tạo, chúng sẽ chọn một điểm cùng với độ tin cậy cao nhất.</p>
	<p class="block_20">Làm việc cùng với lớp mất cân bằng</p>
	<p class="block_1">Một bộ phân loại chỉ tốt nếu như dữ liệu được sử dụng cho đào tạo. Một trong những vấn đề chúng ta thường phải đối mặt trong thực tế là chất lượng của dữ liệu. Để cho một bộ phân loại được hoạt động tốt, là nó cần nhìn thấy những số bằng nhau của các điểm trong mỗi lớp. Nhưng khi chúng ta thu thập dữ liệu trong thực tế, nó không phải luôn luôn đảm bảo mỗi lớp có chính xác số giống với số của điểm dữ liệu của chúng ta. Nếu một lớp có 10 lần các số điểm dữ liệu hơn mỗi lớp khác, thì bộ phân loại sẽ có xu hướng thiên vị hơn cho lớp đó. Vì thế chúng ta cần đảm bảo chúng ta tính toán đúng cho thuật toán mất cân bằng. Hãy xem điều đó cần phải làm thế nào bằng Python.</p>
	<div class="frame_"><p class="block_28"><span class="text_2"># import package cần thiết<br class="calibre4" /></span><span class="text_3">import </span><span class="text_4">sys<br class="calibre4" /></span><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">numpy </span><span class="text_3">as </span><span class="text_4">np<br class="calibre4" /></span><span class="text_3">import </span><span class="text_4">matplotlib.pyplot </span><span class="text_3">as </span><span class="text_4">plt<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.ensemble </span><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">ExtraTreesClassifier<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn </span><span class="text_3">import </span><span class="text_4">model_selection<br class="calibre4" /></span><span class="text_3"><span class="calibre5">from  </span></span><span class="text_4">sklearn.metrics </span><span class="text_3">import </span><span class="text_4">classification_report<br class="calibre4" /></span><span class="text_3"><span class="calibre5">from  </span></span><span class="text_4">utilities </span><span class="text_3">import </span><span class="text_4">visualize_classifier<br class="calibre4" /></span><span class="text_3"><span class="calibre5">from  </span></span><span class="text_4">utilities </span><span class="text_3">import </span><span class="text_4">report_print<br class="calibre4" /></span><span class="text_2"># Chúng ta sẽ sử dụng dữ liệu trong file data/data_imbalance.txt để làm dữ liệu phân tích. Tải dữ liệu. mỗi dòng trong file các giá trị được tách với nhau bởi dấu phẩy. Hai giá trị đầu tiên đối xứng nhau là giá trị đầu vào, và giá trị cuối cùng đại diện cho nhãn đích. Chúng ta có 2 lớp trong bộ dữ liệu(dataset)<br class="calibre4" /></span><span class="text_4">input_file=</span><span class="text_5">"data/data_imbalance.txt"<br class="calibre4" /></span><span class="text_4">data=np.loadtxt(input_file</span><span class="text_3">,</span><span class="text_6">delimiter</span><span class="text_4">=</span><span class="text_5">','</span><span class="text_4">)<br class="calibre4" />X</span><span class="text_3">,</span><span class="text_4">y=data[:</span><span class="text_3">,</span><span class="text_4">:-</span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">data[:</span><span class="text_3">,</span><span class="text_4">-</span><span class="text_7">1</span><span class="text_4">]<br class="calibre4" /></span><span class="text_2"># Chia dữ liệu nhập vào 2 lớp dựa trên nhãn của nó<br class="calibre4" /><br class="calibre4" /></span><span class="text_4">class_0=np.array(X[y==</span><span class="text_7">0</span><span class="text_4">])<br class="calibre4" />class_1=np.array(X[y==</span><span class="text_7">1</span><span class="text_4">])<br class="calibre4" /></span><span class="text_2"># Biểu diễn dữ liệu nhập lên màn hình sử dụng scatter trong plot:<br class="calibre4" /></span><span class="text_4">plt.figure()<br class="calibre4" /><br class="calibre4" />plt.scatter(class_0[:</span><span class="text_3">,</span><span class="text_7">0</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">class_0[:</span><span class="text_3">,</span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_6">s</span><span class="text_4">=</span><span class="text_7">75</span><span class="text_3">,</span><span class="text_6">facecolors</span><span class="text_4">=</span><span class="text_5">'black'</span><span class="text_3">,</span><span class="text_6">edgecolors</span><span class="text_4">=</span><span class="text_5">'black'</span><span class="text_3">,</span><span class="text_6">linewidths</span><span class="text_4">=</span><span class="text_7">1</span><span class="text_3">,</span><span class="text_6">marker</span><span class="text_4">=</span><span class="text_5">"x"</span><span class="text_4">)<br class="calibre4" />plt.scatter(class_1[:</span><span class="text_3">,</span><span class="text_7">0</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">class_1[:</span><span class="text_3">,</span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_6">s</span><span class="text_4">=</span><span class="text_7">75</span><span class="text_3">,</span><span class="text_6">facecolors</span><span class="text_4">=</span><span class="text_5">'gray'</span><span class="text_3">,</span><span class="text_6">edgecolors</span><span class="text_4">=</span><span class="text_5">'black'</span><span class="text_3">,</span><span class="text_6">linewidths</span><span class="text_4">=</span><span class="text_7">1</span><span class="text_3">,</span><span class="text_6">marker</span><span class="text_4">=</span><span class="text_5">"o"</span><span class="text_4">)<br class="calibre4" />plt.title(</span><span class="text_5">"Dữ liệu nhập"</span><span class="text_4">)<br class="calibre4" /><br class="calibre4" /></span><span class="text_2"># Chia dữ liệu để tạo bộ dữ liệu train và testing<br class="calibre4" /></span><span class="text_4">X_train</span><span class="text_3">,</span><span class="text_4">X_test</span><span class="text_3">,</span><span class="text_4">y_train</span><span class="text_3">,</span><span class="text_4">y_test=model_selection.train_test_split(X</span><span class="text_3">,</span><span class="text_4">y</span><span class="text_3">,</span><span class="text_6">test_size</span><span class="text_4">=</span><span class="text_7">0.25</span><span class="text_3">,</span><span class="text_6">random_state</span><span class="text_4">=</span><span class="text_7">5</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2">#Tiếp theo chúng ta cần định nghĩa tham số cho bộ phân loại Extremely Random Forest.<br class="calibre4" /># Chú ý ở đây là một tham số đầu vào được gọi là </span><span class="text_12">balance </span><span class="text_2">tham số này điều khiển việc chúng ta có muốn hoặc không muốn sử dụng thuật toán tính toán cho lớp cân băng.<br class="calibre4" /># </span><span lang="vi" class="text_2">nếu vậy chúng ta </span><span class="text_2"><span class="calibre5">cần thêm một tham số được gọi là  </span></span><span class="text_12">class_weight </span><span class="text_2">tham số này nói cho lớp phân loại biết nó cần cân bằng với tham số này, vậy nó tỷ lệ với số điểm dữ liệu ở mỗi lớp:<br class="calibre4" /># tham số cho ERF<br class="calibre4" /></span><span class="text_4">params={</span><span class="text_5">'n_estimators'</span><span class="text_4">:</span><span class="text_7">100</span><span class="text_3">,</span><span class="text_5">'max_depth'</span><span class="text_4">:</span><span class="text_7">4</span><span class="text_3">,</span><span class="text_5">'random_state'</span><span class="text_4">:</span><span class="text_7">0</span><span class="text_4">}<br class="calibre4" /></span><span class="text_3">if </span><span class="text_8">len</span><span class="text_4">(sys.argv)&gt;</span><span class="text_7">1</span><span class="text_4">:<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_3">if </span><span class="text_4">sys.argv[</span><span class="text_7">1</span><span class="text_4">]==</span><span class="text_5">'balance'</span><span class="text_4">:<br class="calibre4" /><span class="calibre5">        params={</span></span><span class="text_5">'n_estimators'</span><span class="text_4">:</span><span class="text_7">100</span><span class="text_3">,</span><span class="text_5">'max_depth'</span><span class="text_4">:</span><span class="text_7">4</span><span class="text_3">,</span><span class="text_5">'random_state'</span><span class="text_4">:</span><span class="text_7">0</span><span class="text_3">,</span><span class="text_5">'class_weight'</span><span class="text_4">:</span><span class="text_5">'balanced'</span><span class="text_4">}<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_3">else</span><span class="text_4">:<br class="calibre4" /><span class="calibre5">        </span></span><span class="text_3">raise </span><span class="text_8">TypeError</span><span class="text_4">(</span><span class="text_5">"Invalid input argument; Thêm balance vào argument đi pa"</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># Xây dựng, fit để luyện và biểu diễn lớp phân loại sử dụng dữ liệu training:<br class="calibre4" /></span><span class="text_4">classifier=ExtraTreesClassifier(**params)<br class="calibre4" />classifier.fit(X_train</span><span class="text_3">,</span><span class="text_4">y_train)<br class="calibre4" />visualize_classifier(classifier</span><span class="text_3">,</span><span class="text_4">X_train</span><span class="text_3">,</span><span class="text_4">y_train</span><span class="text_3">,</span><span class="text_5">'Dữ liệu training'</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># Predict dầu ra - dự đoán đầu ra và biểu diễn dữ liệu đầu ra:<br class="calibre4" /></span><span class="text_4">y_test_pred=classifier.predict(X_test)<br class="calibre4" />visualize_classifier(classifier</span><span class="text_3">,</span><span class="text_4">X_test</span><span class="text_3">,</span><span class="text_4">y_test</span><span class="text_3">,</span><span class="text_5">'Dữ liệu test'</span><span class="text_4">)<br class="calibre4" /><br class="calibre4" />report_print(classifier</span><span class="text_3">,</span><span class="text_4">[</span><span class="text_5">'Class-0'</span><span class="text_3">,</span><span class="text_5">'Class-1'</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">X_train</span><span class="text_3">,</span><span class="text_4">y_train</span><span class="text_3">,</span><span class="text_4">y_test</span><span class="text_3">,</span><span class="text_4">y_test_pred)</span></p><p class="block_29"></p></div>
	<p class="block_6">&nbsp;</p>
	<p lang="vi" class="block_1">Bạn chạy code trên và sẽ thấy một vài hình output như sau:</p>
	<p class="block_7"><img src="images/000011.png" alt="Image" class="calibre9" /><img src="images/000010.png" alt="Image" class="calibre12" /></p>
	<p class="block_6">&nbsp;</p>
	<p class="block_7"><img src="images/000007.png" alt="Image" class="calibre6" /></p>
	<p class="block_6">&nbsp;</p>
	<p lang="vi" class="block_1">Bạn có thấy khoảng màu đen chính là ranh giới giữa hai lớp. Mảng màu đen trên cùng chính là đại diện cho ranh giới. Output ra Terminal có dạng như sau. </p>
	<p class="block_30"><span class="text_9"><span class="calibre5">              </span></span><span class="text_9">precision<span class="calibre5">    recall  f1-score   support</span></span></p>
	<p class="block_16"><span class="calibre5">     Class-0       0.00      0.00      0.00        69</span></p>
	<p class="block_16"><span class="calibre5">     Class-1       0.82      1.00      0.90       306</span></p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">micro<span class="calibre5"> avg       0.82      0.82      0.82       375</span></span></p>
	<p class="block_17"><span class="text_9"><span class="calibre5">   </span></span><span class="text_9">macro<span class="calibre5"> avg       0.41      0.50      0.45       375</span></span></p>
	<p class="block_16">weighted<span class="calibre5"> avg       0.67      0.82      0.73       375</span></p>
	<p class="block_25">########################################</p>
	<p lang="vi" class="block_1">Và kèm theo 1 warning </p>
	<p lang="vi" class="block_15">UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no </p>
	<p lang="vi" class="block_16">predicted samples.</p>
	<p lang="vi" class="block_25"><span class="calibre5">  'precision', 'predicted', average, warn_for)</span></p>
	<p lang="vi" class="block_1">Bạn thấy warning này bởi vì giá trị là 0 trong hàng đầu tiên, nó là lý do phép lỗi chia cho 0(ZeroDivisionError) khi chúng ta tính f1-score.</p>
	<p lang="vi" class="block_1">Tiếp theo ta thêm tham số balance vào cho file imbalance_class.py</p>
	<p lang="vi" class="block_12">$ python3 imbalance_class.py balance</p>
	<p lang="vi" class="block_1">giờ thì hình output sẽ trông thế này:</p>
	<p class="block_7"><img src="images/000008.png" alt="Image" class="calibre12" /></p>
	<p lang="vi" class="block_1">Bằng cách tính toán sự mất cân bằng của lớp (class imbalance), chúng ta đã phân loại điểm dữ liệu ở class-0 với độ chính xác khác 0 (non-zero accuracy)</p>
	<p lang="vi" class="block_20">Tìm tham số training tối ưu sử dụng tìm kiếm lưới (grid-search)</p>
	<p lang="vi" class="block_1">Khi cúng ta làm việc cùng với các lớp phân loại, chúng ta thường luôn luôn không biết tham số tốt nhất là gì. Bạn không thể thử tất cả các trường hợp (brute-force) lần lượt để tìm số tốt nhất một cách thủ công. Đây là nơi grid-search trở nên thích hợp để dùng. Grid-search cho phép chúng ta chỉ ra một khoảng giá trị và bộ phân loại lớp (the classifier) sẽ tự động chạy vài trường hợp cấu hình khác nhau để tìm ra những tham số thích hợp. Hãy xem làm thế nào để thực hiện nó:</p>
	<div class="frame_"><p class="block_28"><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">numpy </span><span class="text_3">as </span><span class="text_4">np<br class="calibre4" /></span><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">matplotlib.pyplot </span><span class="text_3">as </span><span class="text_4">plt<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.metrics </span><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">classification_report<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn </span><span class="text_3">import </span><span class="text_4">model_selection<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.model_selection </span><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">GridSearchCV<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.ensemble </span><span class="text_3">import </span><span class="text_4">ExtraTreesClassifier<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">utilities </span><span class="text_3">import </span><span class="text_4">visualize_classifier</span><span class="text_3">,</span><span class="text_4">report_print<br class="calibre4" /><br class="calibre4" /></span><span class="text_2"># Chúng ta sử dụng dữ liệu tại file data_random_forests.txt<br class="calibre4" /></span><span class="text_4">input_file=</span><span class="text_5">"data/data_random_forests.txt"<br class="calibre4" /></span><span class="text_4">data=np.loadtxt(input_file</span><span class="text_3">,</span><span class="text_6">delimiter</span><span class="text_4">=</span><span class="text_5">','</span><span class="text_4">)<br class="calibre4" />X</span><span class="text_3">,</span><span class="text_4">y=data[:</span><span class="text_3">,</span><span class="text_4">:-</span><span class="text_7">1</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">data[:</span><span class="text_3">,</span><span class="text_4">-</span><span class="text_7">1</span><span class="text_4">]<br class="calibre4" /></span><span class="text_2">#Chia dữ liệu thành các lớp<br class="calibre4" /></span><span class="text_4">class_0=np.array(X[y==</span><span class="text_7">0</span><span class="text_4">])<br class="calibre4" />class_1=np.array(X[y==</span><span class="text_7">1</span><span class="text_4">])<br class="calibre4" />class_2=np.array(X[y==</span><span class="text_7">2</span><span class="text_4">])<br class="calibre4" /></span><span class="text_2"># chia dữ liệu thành tệp dữ liệu để training và testing<br class="calibre4" /></span><span class="text_4">X_train</span><span class="text_3">,</span><span class="text_4">X_test</span><span class="text_3">,</span><span class="text_4">y_train</span><span class="text_3">,</span><span class="text_4">y_test=model_selection.train_test_split(X</span><span class="text_3">,</span><span class="text_4">y</span><span class="text_3">,</span><span class="text_6">test_size</span><span class="text_4">=</span><span class="text_7">0.25</span><span class="text_3">,</span><span class="text_6">random_state</span><span class="text_4">=</span><span class="text_7">5</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># Tạo một lưới các tham số mà bạn muốn bộ phân loại kiểm tra. Thường thì chúng ta sẽ giữ một tham số hằng ( parameter constant) và những tham số khác nhau (2 tham số thì giữ nguyên một cái còn cái sau thì đưa ra nhiều trường hợp) . Sau đó chúng ta làm ngược lại để chỉ ra sự kết hợp nào là tốt nhất. Trong trường hợp này chúng ta muốn tìm giá trị tốt nhất cho n_estimators và max_depth<br class="calibre4" /># Định nghĩa một lưới tham số<br class="calibre4" /></span><span class="text_4">parameter_grid=[ {</span><span class="text_5">'n_estimators'</span><span class="text_4">: [</span><span class="text_7">100</span><span class="text_4">]</span><span class="text_3">, </span><span class="text_5">'max_depth'</span><span class="text_4">: [</span><span class="text_7">2</span><span class="text_3">, </span><span class="text_7">4</span><span class="text_3">, </span><span class="text_7">7</span><span class="text_3">, </span><span class="text_7">12</span><span class="text_3">, </span><span class="text_7">16</span><span class="text_4">]}</span><span class="text_3">,</span><span class="text_4">{</span><span class="text_5">'max_depth'</span><span class="text_4">: [</span><span class="text_7">4</span><span class="text_4">]</span><span class="text_3">, </span><span class="text_5">'n_estimators'</span><span class="text_4">: [</span><span class="text_7">25</span><span class="text_3">, </span><span class="text_7">50</span><span class="text_3">, </span><span class="text_7">100</span><span class="text_3">,</span><span class="text_7">250</span><span class="text_4">]}]<br class="calibre4" /></span><span class="text_2"># giờ thì định nghĩa số liệu của bộ phân loại sẽ dùng để tìm ra tham số kết hợp tốt nhất<br class="calibre4" /></span><span class="text_4">metrics = [</span><span class="text_5">'precision_weighted'</span><span class="text_3">, </span><span class="text_5">'recall_weighted'</span><span class="text_4">]<br class="calibre4" /></span><span class="text_2"># Cho mỗi số liệu, chúng ta cần chạy grid-search, Nơi mà chúng ta train bộ phân loại cho một bộ kết hợp các tham số<br class="calibre4" /></span><span class="text_3">for </span><span class="text_4">metric </span><span class="text_3">in </span><span class="text_4">metrics:<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5"> Tìm tham số cho: "</span><span class="text_3">,</span><span class="text_4">metric)<br class="calibre4" /><span class="calibre5">    classifier=GridSearchCV(ExtraTreesClassifier(</span></span><span class="text_6">random_state</span><span class="text_4">=</span><span class="text_7">0</span><span class="text_4">)</span><span class="text_3">,</span><span class="text_4">parameter_grid</span><span class="text_3">,</span><span class="text_6">cv</span><span class="text_4">=</span><span class="text_7">5</span><span class="text_3">,</span><span class="text_6">scoring</span><span class="text_4">=metric)<br class="calibre4" /><span class="calibre5">    classifier.fit(X_train</span></span><span class="text_3">,</span><span class="text_4">y_train)<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_2">#print(getattr(classifier, 'cv_results_', None))<br class="calibre4" /><span class="calibre5">    #print(classifier.cv_results_.keys())</span></span><span class="text_2"><br class="calibre4" /><span class="calibre5">    </span></span><span class="text_3">for </span><span class="text_4">params </span><span class="text_3">in </span><span class="text_4">classifier.cv_results_[</span><span class="text_5">'params'</span><span class="text_4">]:<br class="calibre4" /><span class="calibre5">        i=classifier.cv_results_[</span></span><span class="text_5">'params'</span><span class="text_4">].index(params)<br class="calibre4" /><span class="calibre5">        </span></span><span class="text_8">print</span><span class="text_4">(params</span><span class="text_3">,</span><span class="text_5">"----&gt;"</span><span class="text_3">,</span><span class="text_8">round</span><span class="text_4">(classifier.cv_results_[</span><span class="text_5">'mean_test_score'</span><span class="text_4">][i]</span><span class="text_3">,</span><span class="text_7">3</span><span class="text_4">))<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5"> Tham số tốt nhất"</span><span class="text_3">, </span><span class="text_4">classifier.best_params_)<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_2"># print terminal cho mỗi tham số kết hợp:<br class="calibre4" /><br class="calibre4" /><span class="calibre5">    </span></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5">Điểm trên lưới cho tham số trên grid:"</span><span class="text_4">)<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_2">#in report<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_4">y_pred=classifier.predict(X_test)<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5"> Báo cáo hiệu suất:</span><span class="text_3">\n</span><span class="text_5"> "</span><span class="text_4">)<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_8">print</span><span class="text_4">(classification_report(y_test</span><span class="text_3">,</span><span class="text_4">y_pred))</span></p><p class="block_29"></p></div>
	<p lang="vi" class="block_1">Chạy file trên ta có output sau:</p>
	<p lang="vi" class="block_15"><span class="calibre5">Tìm tham số cho:  precision_weighted</span></p>
	<p lang="vi" class="block_16">{'max_depth': 2, 'n_estimators': 100} ----&gt; 0.847</p>
	<p lang="vi" class="block_16">{'max_depth': 4, 'n_estimators': 100} ----&gt; 0.841</p>
	<p lang="vi" class="block_16">{'max_depth': 7, 'n_estimators': 100} ----&gt; 0.844</p>
	<p lang="vi" class="block_16">{'max_depth': 12, 'n_estimators': 100} ----&gt; 0.836</p>
	<p lang="vi" class="block_16">{'max_depth': 16, 'n_estimators': 100} ----&gt; 0.818</p>
	<p lang="vi" class="block_16">{'max_depth': 4, 'n_estimators': 25} ----&gt; 0.846</p>
	<p lang="vi" class="block_16">{'max_depth': 4, 'n_estimators': 50} ----&gt; 0.84</p>
	<p lang="vi" class="block_16">{'max_depth': 4, 'n_estimators': 100} ----&gt; 0.841</p>
	<p lang="vi" class="block_16">{'max_depth': 4, 'n_estimators': 250} ----&gt; 0.845</p>
	<p lang="vi" class="block_16"> Tham số tốt nhất {'max_depth': 2, 'n_estimators': 100}</p>
	<p lang="vi" class="block_16">Điểm trên lưới cho tham số trên grid:</p>
	<p lang="vi" class="block_16"> Báo cáo hiệu suất: </p>
	<p lang="vi" class="block_16"><span class="calibre5">              precision    recall  f1-score   support</span></p>
	<p lang="vi" class="block_16"><span class="calibre5">         0.0       0.94      0.81      0.87        79</span></p>
	<p lang="vi" class="block_16"><span class="calibre5">         1.0       0.81      0.86      0.83        70</span></p>
	<p lang="vi" class="block_16"><span class="calibre5">         2.0       0.83      0.91      0.87        76</span></p>
	<p class="block_18">&nbsp;</p>
	<p lang="vi" class="block_16"><span class="calibre5">   micro avg       0.86      0.86      0.86       225</span></p>
	<p lang="vi" class="block_16"><span class="calibre5">   macro avg       0.86      0.86      0.86       225</span></p>
	<p lang="vi" class="block_25"><span class="calibre5">weighted avg       0.86      0.86      0.86       225</span></p>
	<p lang="vi" class="block_1">và tiếp theo với recall:</p>
	<p lang="vi" class="block_15"><span class="calibre5">Tìm tham số cho:  recall_weighted</span></p>
	<p lang="vi" class="block_16">{'max_depth': 2, 'n_estimators': 100} ----&gt; 0.84</p>
	<p lang="vi" class="block_16">{'max_depth': 4, 'n_estimators': 100} ----&gt; 0.837</p>
	<p lang="vi" class="block_16">{'max_depth': 7, 'n_estimators': 100} ----&gt; 0.841</p>
	<p lang="vi" class="block_16">{'max_depth': 12, 'n_estimators': 100} ----&gt; 0.834</p>
	<p lang="vi" class="block_16">{'max_depth': 16, 'n_estimators': 100} ----&gt; 0.816</p>
	<p lang="vi" class="block_16">{'max_depth': 4, 'n_estimators': 25} ----&gt; 0.843</p>
	<p lang="vi" class="block_16">{'max_depth': 4, 'n_estimators': 50} ----&gt; 0.836</p>
	<p lang="vi" class="block_16">{'max_depth': 4, 'n_estimators': 100} ----&gt; 0.837</p>
	<p lang="vi" class="block_16">{'max_depth': 4, 'n_estimators': 250} ----&gt; 0.841</p>
	<p lang="vi" class="block_16"> Tham số tốt nhất {'max_depth': 4, 'n_estimators': 25}</p>
	<p lang="vi" class="block_16">Điểm trên lưới cho tham số trên grid:</p>
	<p lang="vi" class="block_16"> Báo cáo hiệu suất: </p>
	<p lang="vi" class="block_16"><span class="calibre5">              precision    recall  f1-score   support</span></p>
	<p lang="vi" class="block_16"><span class="calibre5">         0.0       0.93      0.84      0.88        79</span></p>
	<p lang="vi" class="block_16"><span class="calibre5">         1.0       0.85      0.86      0.85        70</span></p>
	<p lang="vi" class="block_16"><span class="calibre5">         2.0       0.84      0.92      0.88        76</span></p>
	<p lang="vi" class="block_16"><span class="calibre5">   micro avg       0.87      0.87      0.87       225</span></p>
	<p lang="vi" class="block_16"><span class="calibre5">   macro avg       0.87      0.87      0.87       225</span></p>
	<p lang="vi" class="block_25"><span class="calibre5">weighted avg       0.87      0.87      0.87       225</span></p>
	<p class="block_6">&nbsp;</p>
	<p class="block_6">&nbsp;</p>
	<p class="block_6">&nbsp;</p>
	<p lang="vi" class="block_1">Ta thấy kết quả thu được là khác nhau bởi vì precision weight,và recall weight là hai số liệu khác nhau và đòi hỏi kết hợp các tham số khác nhau.</p>
	<p lang="vi" class="block_20">Tính toán sự quan trọng tương đối</p>
	<p class="block_1"><span lang="vi" class="calibre15">Khi chúng ta làm việc cùng với một tập dữ liệu (dataset) có N-chiều điểm dữ liệu, chúng ta phải hiểu tất cả các tính năng không phải đều quan trọng như nhau. Một vài cái cần phải phân biệt với những cái khác. Nếu chúng ta có những thông tin này, chúng ta ó thể dùng nó để giảm các chiều lại. Nó rất hữu dụng trong việc giảm sự phức tạp và tăng tốc độ của thuật tóa. Thi thoảng một vài tính năng thật sự dư thừa. vì thế chúng cần phải "di dời" ra khỏi tập dự liệu. Chúng ta sẽ sử dụng AdaBoost Regressor để tính toán tính năng quan trọng. </span><i lang="vi" class="calibre7">AdaBoost, </i><span lang="vi" class="calibre15">là từ viết tắt của Adaptive Boosting &ndash; Tăng cường thích ứng, là một thuật toán thường được dùng kết hợp với những thuật toán Machine Learning khác để tăng hiệu quả. Trong AdaBoost, một điểm dữ liệu luyên tập (training data point) được rút ra từ một </span><b lang="vi" class="calibre1">bộ phân phối</b><span lang="vi" class="calibre15"> để luyện cho bộ phân loại hiện tại. Bộ phân phối này được cập nhật lặp đi lặp lại để các bộ phân loại tiếp theo tập trung vào những </span><b lang="vi" class="calibre1">điểm dữ liệu khó</b><span lang="vi" class="calibre15">. Điểm dữ liệu khó là những điểm dữ liệu phân loại sai. Điều này được thực hiện bởi cách cập nhật các</span><b lang="vi" class="calibre1"> bộ phân phối </b><span lang="vi" class="calibre15">ở mỗi bước. Điều này sẽ làm cho điểm dữ liệu mà trước đó phân loại sai nhiều khả năng xuất hiện trong tập dữ liệu mẫu tiếp theo để training. Những bộ phân loại này sau đó sẽ được xếp chồng lên nhau và quyết định sẽ được đưa ra thông qua bầu chọn đa số.</span></p>
	<p class="block_1">Bắt đầu với đoạn code sau</p>
	<div class="frame_"><p class="block_28"><span class="text_3">import </span><span class="text_4">numpy </span><span class="text_3">as </span><span class="text_4">np<br class="calibre4" /></span><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">matplotlib.pyplot </span><span class="text_3">as </span><span class="text_4">plt<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.ensemble </span><span class="text_3">import </span><span class="text_4">AdaBoostClassifier<br class="calibre4" /></span><span class="text_3"><span class="calibre5">from  </span></span><span class="text_4">sklearn.tree </span><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">DecisionTreeRegressor<br class="calibre4" /><br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn </span><span class="text_3">import </span><span class="text_4">datasets<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.metrics </span><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">mean_squared_error</span><span class="text_3">,</span><span class="text_4">explained_variance_score<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.model_selection </span><span class="text_3">import </span><span class="text_4">train_test_split<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.utils </span><span class="text_3">import </span><span class="text_4">shuffle<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.svm </span><span class="text_3">import </span><span class="text_4">SVC<br class="calibre4" /></span><span class="text_2"># Đầu tiên ta sử dụng data có sẵn trong scikit-learn:<br class="calibre4" /></span><span class="text_4">data=datasets.load_diabetes()<br class="calibre4" /></span><span class="text_2"># Xáo trộn dataset để không làm phân tích của chúng ta bị giống nhau<br class="calibre4" /></span><span class="text_4">X</span><span class="text_3">,</span><span class="text_4">y=data[</span><span class="text_5">'data'</span><span class="text_4">]</span><span class="text_3">,</span><span class="text_4">data[</span><span class="text_5">'target'</span><span class="text_4">]<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_2">#shuffle(iris.data,iris.target,random_state=7)<br class="calibre4" />#shuffle(data[:,:-1],data[:,-1],random_state=7) #<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(data.feature_names)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"*"</span><span class="text_4">*</span><span class="text_7">40</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2">#print(y)<br class="calibre4" /># Chia dữ liệu để train và test<br class="calibre4" /></span><span class="text_4">X_train</span><span class="text_3">,</span><span class="text_4">X_test</span><span class="text_3">,</span><span class="text_4">y_train</span><span class="text_3">,</span><span class="text_4">y_test=train_test_split(X</span><span class="text_3">,</span><span class="text_4">y</span><span class="text_3">,</span><span class="text_6">test_size</span><span class="text_4">=</span><span class="text_7">0.2</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># Định nghĩa và train AdaBoost sử dụng Decision Tree regressor như là một mô hình riêng<br class="calibre4" /></span><span class="text_4">svc=SVC(</span><span class="text_6">probability</span><span class="text_4">=</span><span class="text_3">True,</span><span class="text_6">kernel</span><span class="text_4">=</span><span class="text_5">'linear'</span><span class="text_4">)<br class="calibre4" />DTR=DecisionTreeRegressor(</span><span class="text_6">max_depth</span><span class="text_4">=</span><span class="text_7">4</span><span class="text_4">)<br class="calibre4" />regressor=AdaBoostClassifier(</span><span class="text_6">base_estimator</span><span class="text_4">=</span><span class="text_3">None,</span><span class="text_6">algorithm</span><span class="text_4">=</span><span class="text_5">"SAMME"</span><span class="text_3">,</span><span class="text_6">n_estimators</span><span class="text_4">=</span><span class="text_7">50</span><span class="text_3">,</span><span class="text_6">learning_rate</span><span class="text_4">=</span><span class="text_7">2</span><span class="text_4">)<br class="calibre4" />model=regressor.fit(X_train</span><span class="text_3">,</span><span class="text_4">y_train)<br class="calibre4" /></span><span class="text_2"># Ước tính hiệu suất của phép hồi quy (regressor):<br class="calibre4" /></span><span class="text_4">y_pred=model.predict(X_test)<br class="calibre4" />mse=mean_squared_error(y_test</span><span class="text_3">,</span><span class="text_4">y_pred)<br class="calibre4" />evs=explained_variance_score(y_test</span><span class="text_3">,</span><span class="text_4">y_pred)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5">AdaptiveBoost REGRESSOR"</span><span class="text_4">)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5">Mean square error"</span><span class="text_3">,</span><span class="text_8">round</span><span class="text_4">(mse</span><span class="text_3">,</span><span class="text_7">2</span><span class="text_4">))<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"</span><span class="text_3">\n</span><span class="text_5">Variance Score: "</span><span class="text_3">,</span><span class="text_8">round</span><span class="text_4">(evs</span><span class="text_3">,</span><span class="text_7">2</span><span class="text_4">))<br class="calibre4" /></span><span class="text_2"># Phép hồi quy này có một phương thức có sẵn có thể gọi để tính độ quan trọng tính năng tương đối:<br class="calibre4" /></span><span class="text_4">feature_importances=regressor.feature_importances_<br class="calibre4" />feature_name=data.feature_names<br class="calibre4" /></span><span class="text_2"># Đơn giản hóa giá trị của độ quan trọng tính năng tương đối:<br class="calibre4" /></span><span class="text_4">feature_importances=</span><span class="text_7">100.0</span><span class="text_4">*(feature_importances/</span><span class="text_8">max</span><span class="text_4">(feature_importances))<br class="calibre4" /></span><span class="text_2"># Sắp xếp feature lại (sort) để có thể phác họa thành đồ thị:<br class="calibre4" /></span><span class="text_4">index_sorted=np.flipud(np.argsort(feature_importances))<br class="calibre4" /></span><span class="text_2"># Sắp xếp điểm trên trục X để làm đồ thị dạng biểu đồ<br class="calibre4" /></span><span class="text_4">pos=np.arange(index_sorted.shape[</span><span class="text_7">0</span><span class="text_4">])+</span><span class="text_7">1<br class="calibre4" /></span><span class="text_2"># vẽ biểu đồ với plot<br class="calibre4" /></span><span class="text_4">plt.figure()<br class="calibre4" />plt.bar(pos</span><span class="text_3">,</span><span class="text_4">feature_importances[index_sorted]</span><span class="text_3">,</span><span class="text_6">align</span><span class="text_4">=</span><span class="text_5">'center'</span><span class="text_4">)<br class="calibre4" />plt.xticks(pos</span><span class="text_3">,</span><span class="text_4">np.array(feature_name)[index_sorted])<br class="calibre4" />plt.ylabel(</span><span class="text_5">'Độ quan trọng tương đối'</span><span class="text_4">)<br class="calibre4" />plt.title(</span><span class="text_5">"Độ quan trọng của tính năng sử dụng AdaBoost"</span><span class="text_4">)<br class="calibre4" />plt.show()</span></p><p class="block_29"></p></div>
	<p class="block_6">&nbsp;</p>
	<p class="block_1">và ta có biểu đồ cột như sau <img src="images/000004.png" alt="Image" class="calibre6" /></p>
	<p class="block_1">Nhìn vào biểu đồ trên ta có thể thấy đối với việc lấy dữ liệu để chuẩn đoán bệnh tiểu đường thì chỉ số bmi là chỉ số quan trọng nhất cần được chú ý.</p>
	<p class="block_20">Dự đoán tình hình giao thông sử dụng Extremely Random Forest regressor</p>
	<p class="block_1">Hãy ứng dụng những cái ta đã học ở phần trước để giải quyết một vấn đề thực tế. Chúng ta có thể sử dụng dữ liệu ở đây : <a class="text_13" href="https://archive.ics.uci.edu/ml/datasets/Dodgers+Loop+Sensor">https://archive.ics.uci.edu/ml/datasets/Dodgers+Loop+Sensor</a> . Bộ dữ liệu này bao gồm dữ liệu đã tính toán số xe cộ di truyển trên đường trong các trận bóng chày được chơi ở sân Los Angerles Dodgers. Để dữ liệu sẵn sàng để phân tích chúng ta phải xử lý thô nó trước. Dữ liệu xử lý thô có trong file traffic_data.txt. trong file này mỗi dòng dùng dấu ',' để chia các chữ ra. Hãy xem dòng đầu tiên như thế nào: </p>
	<p class="block_31">Tuesday,00:00,San Francisco,no,3</p>
	<p class="block_1">Nhìn vào dữ liệu trên ta có thể thấy nó có dạng sau: Ngày trong tuần, thời gian trong ngày, tên đội đối thủ,giá trị binarray chỉ ra trận đấu đó có đang diễn ra hay không (yes,no), cuối cùng là số phương tiện di chuyển.</p>
	<p class="block_1">Nhiệm vụ của chúng ta là dự đoán số phương tiện đang di chuyển bằng cách đưa ra những thông tin. Từ kết quả output được lấy giá trị liên tục, chúng ta cần xây dựng một mô hình có thể dự đoán được kết quả output. (từ giờ mình sẽ dùng output-đầu ra và input-đầu vào ko dịch sang tiếng việt 2 từ này nữa). Chúng ta sẽ sử dụng ERF để xây dựng mô hình này.</p>
	<p class="block_1">Tạo file python với tên gọi traffic_prediction.py</p>
	<div class="frame_"><p class="block_28"><span class="text_3">import </span><span class="text_4">numpy </span><span class="text_3">as </span><span class="text_4">np<br class="calibre4" /></span><span class="text_3">import </span><span class="text_4">matplotlib.pyplot </span><span class="text_3">as </span><span class="text_4">plt<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.metrics </span><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">classification_report</span><span class="text_3">,</span><span class="text_4">mean_absolute_error<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn </span><span class="text_3"><span class="calibre5">import  </span></span><span class="text_4">model_selection</span><span class="text_3">,</span><span class="text_4">preprocessing<br class="calibre4" /></span><span class="text_3">from </span><span class="text_4">sklearn.ensemble </span><span class="text_3">import </span><span class="text_4">ExtraTreesRegressor<br class="calibre4" /><br class="calibre4" /></span><span class="text_2"># Load data từ file txt<br class="calibre4" /></span><span class="text_4">input_file=</span><span class="text_5">"data/traffic_data.txt"<br class="calibre4" /></span><span class="text_4">data=[]<br class="calibre4" /></span><span class="text_3">with </span><span class="text_8">open</span><span class="text_4">(input_file</span><span class="text_3">,</span><span class="text_5">'r'</span><span class="text_4">) </span><span class="text_3">as </span><span class="text_4">f:<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_3">for </span><span class="text_4">line </span><span class="text_3">in </span><span class="text_4">f.readlines():<br class="calibre4" /><span class="calibre5">        items=line[:-</span></span><span class="text_7">1</span><span class="text_4">].split(</span><span class="text_5">','</span><span class="text_4">)<br class="calibre4" /><span class="calibre5">        data.append(items)</span></span><span class="text_4"><br class="calibre4" />data=np.array(data)<br class="calibre4" /></span><span class="text_2"># Chúng ta cần mã hóa những features không phải là số trong dữ liệu. Chúng ta cũng cần đảm bảo là chúng ta không mã hóa nhầm số. Mỗi tính năng (features) cần được mã hóa cũng cần phải có một nhãn được mã hóa riêng biệt. Chúng ta cần theo dõi những mã hóa này bởi vì chúng ta sẽ cần chúng khi chúng ta muốn tính toán output cho một điểm dữ liệu không biết.<br class="calibre4" />#Giờ thì tạo một bộ mã hóa nhãn<br class="calibre4" /># Chuyển đổi dữ liệu chữ thành dữ liệu số<br class="calibre4" /></span><span class="text_4">label_encoder=[]<br class="calibre4" />X_encoded=np.empty(data.shape)<br class="calibre4" /></span><span class="text_3">for </span><span class="text_4">i</span><span class="text_3">,</span><span class="text_4">item </span><span class="text_3">in </span><span class="text_8">enumerate</span><span class="text_4">(data[</span><span class="text_7">0</span><span class="text_4">]):<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_3">if </span><span class="text_4">item.isdigit():<br class="calibre4" /><span class="calibre5">        X_encoded[:</span></span><span class="text_3">,</span><span class="text_4">i]=data[:</span><span class="text_3">,</span><span class="text_4">i]<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_3">else</span><span class="text_4">:<br class="calibre4" /><span class="calibre5">        label_encoder.append(preprocessing.LabelEncoder())</span></span><span class="text_4"><br class="calibre4" /><span class="calibre5">        X_encoded[:</span></span><span class="text_3">,</span><span class="text_4">i]=label_encoder[-</span><span class="text_7">1</span><span class="text_4">].fit_transform(data[:</span><span class="text_3">,</span><span class="text_4">i])<br class="calibre4" />X=X_encoded[:</span><span class="text_3">,</span><span class="text_4">:-</span><span class="text_7">1</span><span class="text_4">].astype(</span><span class="text_8">int</span><span class="text_4">)<br class="calibre4" />y=X_encoded[:</span><span class="text_3">,</span><span class="text_4">-</span><span class="text_7">1</span><span class="text_4">].astype(</span><span class="text_8">int</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># Chia dữ liệu vào tập training và testing<br class="calibre4" /></span><span class="text_4">X_train</span><span class="text_3">,</span><span class="text_4">X_test</span><span class="text_3">,</span><span class="text_4">y_train</span><span class="text_3">,</span><span class="text_4">y_test=model_selection.train_test_split(X</span><span class="text_3">,</span><span class="text_4">y</span><span class="text_3">,</span><span class="text_6">test_size</span><span class="text_4">=</span><span class="text_7">0.25</span><span class="text_3">,</span><span class="text_6">random_state</span><span class="text_4">=</span><span class="text_7">5</span><span class="text_4">)<br class="calibre4" /></span><span class="text_2"># Train một model dùng Extremely Forest<br class="calibre4" /></span><span class="text_4">regressor=ExtraTreesRegressor(</span><span class="text_6">n_estimators</span><span class="text_4">=</span><span class="text_7">100</span><span class="text_3">,</span><span class="text_6">max_depth</span><span class="text_4">=</span><span class="text_7">4</span><span class="text_3">,</span><span class="text_6">random_state</span><span class="text_4">=</span><span class="text_7">0</span><span class="text_4">)<br class="calibre4" />model=regressor.fit(X_train</span><span class="text_3">,</span><span class="text_4">y_train)<br class="calibre4" /></span><span class="text_2"># Tinhs toán hiệu suất của mô hình dựa trên dữ liệu test<br class="calibre4" /></span><span class="text_4">y_pred=model.predict(X_test)<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"Mean absolute error: "</span><span class="text_3">,</span><span class="text_8">round</span><span class="text_4">(mean_absolute_error(y_test</span><span class="text_3">,</span><span class="text_4">y_pred)</span><span class="text_3">,</span><span class="text_7">2</span><span class="text_4">))<br class="calibre4" /></span><span class="text_2"># Bây giờ sẽ xem xét làm sao để tính Output trên một điểm dữ liệu không biết. Chúng ta sẽ sử dụng những bộ mã hóa nhãn để chuyển đổi những tính năng không phải số thành những giá trị số:<br class="calibre4" /></span><span class="text_4">test_datapoint=[</span><span class="text_5">'Tuesday'</span><span class="text_3">,</span><span class="text_5">'02:00'</span><span class="text_3">,</span><span class="text_5">'San Francisco'</span><span class="text_3">,</span><span class="text_5">'no'</span><span class="text_4">]<br class="calibre4" />test_datapoint_encoded=[-</span><span class="text_7">1</span><span class="text_4">]*</span><span class="text_8">len</span><span class="text_4">(test_datapoint)<br class="calibre4" />count=</span><span class="text_7">0<br class="calibre4" /></span><span class="text_3">for </span><span class="text_4">i</span><span class="text_3">,</span><span class="text_4">item </span><span class="text_3">in </span><span class="text_8">enumerate</span><span class="text_4">(test_datapoint):<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_3">if </span><span class="text_4">item.isdigit():<br class="calibre4" /><span class="calibre5">        test_datapoint_encoded[i]=</span></span><span class="text_8">int</span><span class="text_4">(test_datapoint[i])<br class="calibre4" /><span class="calibre5">    </span></span><span class="text_3">else</span><span class="text_4">:<br class="calibre4" /><span class="calibre5">        test_datapoint_encoded[i]=</span></span><span class="text_8">int</span><span class="text_4">(label_encoder[count].transform([test_datapoint[i]]))<br class="calibre4" /><span class="calibre5">        count+=</span></span><span class="text_7">1<br class="calibre4" /></span><span class="text_4">test_datapoint_encoded=np.array(test_datapoint_encoded)<br class="calibre4" /></span><span class="text_2"># Dự đoán kết quả Output<br class="calibre4" /></span><span class="text_8">print</span><span class="text_4">(</span><span class="text_5">"Dự đoán số lượng xe là: "</span><span class="text_3">,</span><span class="text_4">model.predict([test_datapoint_encoded])[</span><span class="text_7">0</span><span class="text_4">])</span></p><p class="block_29"></p></div>
	<p class="block_1">Kết quả ở Terminal:</p>
	<p class="block_15"><span class="calibre5">Mean absolute error:  7.42</span></p>
	<p class="block_16">Dự đoán số lượng xe<span class="calibre5"> là:  4.937275750980459</span></p>
	<p class="block_25">Process finished with exit code 0</p>
	<p class="block_20">Tổng kết</p>
	<p class="block_1">Trong chương này chúng ta đã học về Ensemble Learning và học cách làm thế nào để ứng dụng nó trong thực tế. Chúng ta bàn luận về Decision Tree (Cây quyết định) và cách xây dựng một mô hình phân loại dựa trên nó. </p>
	<p class="block_1">Chúng ta đã học về Random Forest và Extremely Random Forest, và cách xây dựng mô hình phân loại dựa trên chúng. Chúng ta hiểu cách để ước tính mức độ tin cậy của một mô hình dự đoán. Chúng ta cũng học cách làm thế nào để giải quyết vấn đề mất cân bằng giữa các lớp.</p>
	<p class="block_1">Chúng ta đã thảo luận về cách tìm tham số tối ưu để xây dựng những mô hình sử dụng tìm kiếm lưới (grid-search). Chúng ta học về cách tính độ quan trọng tính năng tương đối. Và sau đó áp dụng kỹ thuật Ensemble <span class="calibre2">Learning  để</span> giải quyết vấn đề trong thực tế là, thử dự đoán mật độ giao thông sử dung Extremely Random Forests.</p>
	<p class="block_1">Trong chương tiếp theo chúng ta sẽ thảo luận về học không giám sát và cách phát hiện mẫu dữ liệu thị trường chứng khoán.</p>
	<p class="block_6">&nbsp;</p>

</div>

</body></html>

<footer class=" footline" >
	
</footer>


        
        </div> 
        

      </div>

    <div id="navigation">
        
        
        
        
            
            
                
                    
                    
                
                

                    
                    
                        
                    
                    

                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                        
                        
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
                        
            
            
                
                    
                
                

                    
                    
                    

                    
            
        
                    
            
        
        
        


	 
	 
		
			<a class="nav nav-prev" href="/ai-with-python/chapter2/" title="C2: Classification and Regression"> <i class="fa fa-chevron-left"></i></a>
		
		
			<a class="nav nav-next" href="/ai-with-python/chapter4/" title="C4: Detecting Patterns with Unsupervised Learning" style="margin-right: 0px;"><i class="fa fa-chevron-right"></i></a>
		
	
    </div>

    </section>
    
    <div style="left: -1000px; overflow: scroll; position: absolute; top: -1000px; border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;">
      <div style="border: none; box-sizing: content-box; height: 200px; margin: 0px; padding: 0px; width: 200px;"></div>
    </div>
    <script src="/js/clipboard.min.js?1572419511"></script>
    <script src="/js/perfect-scrollbar.min.js?1572419511"></script>
    <script src="/js/perfect-scrollbar.jquery.min.js?1572419511"></script>
    <script src="/js/jquery.sticky.js?1572419511"></script>
    <script src="/js/featherlight.min.js?1572419511"></script>
    <script src="/js/highlight.pack.js?1572419511"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="/js/modernizr.custom-3.6.0.js?1572419511"></script>
    <script src="/js/learn.js?1572419511"></script>
    <script src="/js/hugo-learn.js?1572419511"></script>

    <link href="/mermaid/mermaid.css?1572419511" rel="stylesheet" />
    <script src="/mermaid/mermaid.js?1572419511"></script>
    <script>
        mermaid.initialize({ startOnLoad: true });
    </script>
    

  </body>
</html>

